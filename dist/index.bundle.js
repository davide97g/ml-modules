/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./test/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/could-be-utils/index.js":
/*!**********************************************!*\
  !*** ./node_modules/could-be-utils/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//require all the modules\r\nconst array = __webpack_require__(/*! ./src/array/array */ \"./node_modules/could-be-utils/src/array/array.js\");\r\nconst random = __webpack_require__(/*! ./src/random/random */ \"./node_modules/could-be-utils/src/random/random.js\");\r\nconst distances = __webpack_require__(/*! ./src/distances/distances */ \"./node_modules/could-be-utils/src/distances/distances.js\");\r\nconst statistics = __webpack_require__(/*! ./src/statistics/statistics */ \"./node_modules/could-be-utils/src/statistics/statistics.js\");\r\n\r\n//test\r\n// console.info(\"--- array\");\r\n// let zeros = array.zeros(5);\r\n// console.table(zeros);\r\n// let arrayW = array.arrayWith(\"TEST\", 10);\r\n// console.table(arrayW);\r\n\r\n// console.info(\"--- random\");\r\n// let ri = random.randi(0, 10);\r\n// console.info(ri);\r\n// let rf = random.randf(0, 10);\r\n// console.info(rf);\r\n\r\n// console.info(\"--- distances\");\r\n// let distance = new distances();\r\n// let point1 = [1, 1];\r\n// let point2 = [2, 2];\r\n// console.info(distance.minkowski(point1, point2));\r\n\r\n// console.info(\"--- statistics\");\r\n// let data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\r\n// let arrayData = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]];\r\n// let singleArrayData = [[1], [2], [3], [4], [5]];\r\n\r\n// console.info(statistics.average(data));\r\n// console.table(statistics.average(arrayData));\r\n// console.table(statistics.average(singleArrayData));\r\n// console.table(statistics.variance(data));\r\n// console.table(statistics.variance(arrayData));\r\n// console.table(statistics.variance(singleArrayData));\r\n\r\n//expose all the modules\r\nmodule.exports = {\r\n  array: array,\r\n  random: random,\r\n  distances: distances,\r\n  statistics: statistics\r\n};\r\n\n\n//# sourceURL=webpack:///./node_modules/could-be-utils/index.js?");

/***/ }),

/***/ "./node_modules/could-be-utils/src/array/array.js":
/*!********************************************************!*\
  !*** ./node_modules/could-be-utils/src/array/array.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\r\n * @name utils.js\r\n * @description\r\n * a list of utility functions for array\r\n * @copyright Davide Ghiotto\r\n */\r\n\r\n// create vector of zeros of length n\r\nfunction zeros(n) {\r\n  if (n === 0) return [];\r\n  let a = new Array(n);\r\n  for (let i = 0; i < n; i++) {\r\n    a[i] = 0;\r\n  }\r\n  return a;\r\n}\r\n\r\n//create a copy of the original array\r\nfunction copyArray(v) {\r\n  let a = new Array(v.length);\r\n  for (let i = 0; i < v.length; i++) {\r\n    a[i] = v[i];\r\n  }\r\n  return a;\r\n}\r\n\r\n//create an array based on copy of the value passed from input\r\nfunction arrayWith(value, N) {\r\n  if (N === 0) return [];\r\n  let a = new Array(N);\r\n  for (let i = 0; i < N; i++) {\r\n    a[i] = value;\r\n  }\r\n  return a;\r\n}\r\n\r\nfunction objectToArray(array) {\r\n  let result = [];\r\n  array.forEach(data => result.push([data.x, data.y]));\r\n  return result;\r\n}\r\n\r\nfunction arrayToObject(array) {\r\n  let result = [];\r\n  array.forEach(data => result.push({ x: data[0], y: data[1] }));\r\n  return result;\r\n}\r\n\r\nmodule.exports = {\r\n  arrayToObject: arrayToObject,\r\n  objectToArray: objectToArray,\r\n  arrayWith: arrayWith,\r\n  copyArray: copyArray,\r\n  zeros: zeros\r\n};\r\n\n\n//# sourceURL=webpack:///./node_modules/could-be-utils/src/array/array.js?");

/***/ }),

/***/ "./node_modules/could-be-utils/src/distances/distances.js":
/*!****************************************************************!*\
  !*** ./node_modules/could-be-utils/src/distances/distances.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/**\r\n *\r\n * @description\r\n * Class used to handle distances functions\r\n * @example\r\n * //new instance\r\n * let distances = new Distances();\r\n * //define two points\r\n * let point1 = [1,3];\r\n * let point2 = [4,-2];\r\n * //minkowski distance from two points\r\n * let minkowski_distance = distances.minkowski(point1,point2);\r\n * //chebyshev distance from two points\r\n * let chebyshev_distance = distances.chebyshev(point1,point2);\r\n * //mahalanobis distance from two points\r\n * let mahalanobis_distance = distances.mahalanobis(point1,point2);\r\n * //setting the grade for minkowski\r\n * distances.setMinkowskiDegree(2);\r\n */\r\n\r\nconst variance = __webpack_require__(/*! ../statistics/statistics */ \"./node_modules/could-be-utils/src/statistics/statistics.js\").variance;\r\nconst Distances = function() {\r\n  this.p = 1;\r\n  this.data = [];\r\n  this.variance = 0;\r\n  this.default = function() {};\r\n};\r\n\r\nDistances.prototype = {\r\n  /**\r\n   * Sets the dataset and calculate the variance\r\n   * @param data {data} dataset to be used for the distances calculations\r\n   */\r\n  setDataSet: function(data) {\r\n    this.data = data;\r\n    this.variance = variance(data);\r\n  },\r\n\r\n  /**\r\n   * Set the default function for the distance calculation\r\n   * @param {String} algorithm\r\n   */\r\n  setDefault: function(algorithm) {\r\n    if (algorithm === \"minkowski\") this.default = this.minkowski;\r\n    else if (algorithm === \"chebyshev\") this.default = this.chebyshev;\r\n    else if (algorithm === \"mahalanobis\") this.default = this.mahalanobis;\r\n    else this.default = this.minkowski;\r\n  },\r\n\r\n  /**\r\n   * Returns the distance between two points using the default algorithm\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} distance\r\n   */\r\n  of: function(point1, point2) {\r\n    try {\r\n      return this.default(point1, point2);\r\n    } catch (e) {\r\n      console.warn(e);\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Sets the degree of the minkowski distance\r\n   * @param p {Number} the degree for minkowski distance\r\n   */\r\n  setMinkowskiDegree: function(p) {\r\n    this.p = p || this.p;\r\n    if (this.p < 1) this.p = 1;\r\n  },\r\n\r\n  /**\r\n   * Returns the minkowski distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} minkowski distance\r\n   */\r\n  minkowski: function(point1, point2) {\r\n    if (point1.length !== point2.length) {\r\n      console.warn(\"point of different lengths\");\r\n      return;\r\n    }\r\n    let sum = 0;\r\n    for (let i = 0; i < point1.length; i++)\r\n      sum += Math.pow(Math.abs(point1[i] - point2[i]), this.p);\r\n    return Math.pow(sum, 1 / this.p);\r\n  },\r\n\r\n  /**\r\n   * Returns the chebyshev distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} chebyshev distance between the two points\r\n   */\r\n  chebyshev: function(point1, point2) {\r\n    let value;\r\n    let max = 0;\r\n    for (let i = 0; i < point1.length; i++) {\r\n      value = Math.abs(point2[i] - point1[i]);\r\n      if (value > max) max = value;\r\n    }\r\n    return max;\r\n  },\r\n\r\n  /**\r\n   * Returns the mahalanobis distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} mahalanobis distance between the two points\r\n   */\r\n  mahalanobis: function(point1, point2) {\r\n    if (this.data.length === 0) throw \"no data\";\r\n    let sum = 0;\r\n    for (let i = 0; i < point1.length; i++)\r\n      sum += Math.pow(point1[i] - point2[i], 2) / Math.pow(this.variance[i], 2);\r\n    return Math.sqrt(sum);\r\n  }\r\n};\r\n\r\nmodule.exports = Distances;\r\n\n\n//# sourceURL=webpack:///./node_modules/could-be-utils/src/distances/distances.js?");

/***/ }),

/***/ "./node_modules/could-be-utils/src/random/random.js":
/*!**********************************************************!*\
  !*** ./node_modules/could-be-utils/src/random/random.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// generate random float between a and b (b excluded)\r\nfunction randf(a, b) {\r\n  return Math.random() * (b - a) + a;\r\n}\r\n\r\n// generate random integer between a and b (b excluded)\r\nfunction randi(a, b) {\r\n  return Math.floor(Math.random() * (b - a) + a);\r\n}\r\n\r\nmodule.exports = {\r\n  randf: randf,\r\n  randi: randi\r\n};\r\n\n\n//# sourceURL=webpack:///./node_modules/could-be-utils/src/random/random.js?");

/***/ }),

/***/ "./node_modules/could-be-utils/src/statistics/statistics.js":
/*!******************************************************************!*\
  !*** ./node_modules/could-be-utils/src/statistics/statistics.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const zeros = __webpack_require__(/*! ../array/array */ \"./node_modules/could-be-utils/src/array/array.js\").zeros;\r\n\r\nfunction variance(data) {\r\n  let avg = average(data);\r\n  let variance;\r\n  let N = data.length;\r\n  if (avg.length !== undefined) {\r\n    let M = avg.length;\r\n    variance = zeros(M);\r\n    for (let i = 0; i < M; i++) {\r\n      for (let j = 0; j < N; j++) {\r\n        variance[i] += Math.pow(data[j][i] - avg[i], 2);\r\n      }\r\n      variance[i] = Math.sqrt(variance[i] / N);\r\n    }\r\n  } else {\r\n    variance = 0;\r\n    for (let i = 0; i < N; i++) {\r\n      variance += Math.pow(data[i] - avg, 2);\r\n    }\r\n    variance = Math.sqrt(variance / N);\r\n  }\r\n  return variance;\r\n}\r\n\r\nfunction average(data) {\r\n  let avg;\r\n  let N = data.length;\r\n  let M = data[0].length;\r\n  if (M !== undefined) {\r\n    avg = zeros(M);\r\n    for (let i = 0; i < M; i++) {\r\n      for (let j = 0; j < N; j++) {\r\n        avg[i] += data[j][i];\r\n      }\r\n      avg[i] /= N;\r\n    }\r\n  } else {\r\n    //just the classic average\r\n    avg = 0;\r\n    for (let i = 0; i < N; i++) avg += data[i];\r\n    avg /= N;\r\n  }\r\n  return avg;\r\n}\r\n\r\nmodule.exports = {\r\n  average: average,\r\n  variance: variance\r\n};\r\n\n\n//# sourceURL=webpack:///./node_modules/could-be-utils/src/statistics/statistics.js?");

/***/ }),

/***/ "./src/js/dataset.js":
/*!***************************!*\
  !*** ./src/js/dataset.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/** YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name dataset.js\r\n * @description\r\n * function that generates new datasets that shared a common structure based on the function they use.\r\n * @copyright Davide Ghiotto\r\n */\r\nconst random = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\").random;\r\nconst dataset_generator = function() {};\r\ndataset_generator.prototype = {\r\n  randomData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    for (let i = 0; i < N; i++) {\r\n      data[i] = [random.randf(-3, 3), random.randf(-3, 3)];\r\n      if (random.randi(0, 2)) labels[i] = 1;\r\n      else labels[i] = -1;\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  circleMultipleData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let radius;\r\n    for (let i = 0; i < N; i++) {\r\n      if (i < N / 3) {\r\n        radius = random.randf(0.1, 2.5);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius;\r\n        let y = Math.sin(angle) * radius;\r\n        data[i] = [x, y];\r\n        labels[i] = 1;\r\n      } else if (i < (N * 2) / 3) {\r\n        radius = random.randf(2.5, 3);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius;\r\n        let y = Math.sin(angle) * radius;\r\n        data[i] = [x, y];\r\n        labels[i] = -1;\r\n      } else {\r\n        radius = random.randf(3, 4);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius;\r\n        let y = Math.sin(angle) * radius;\r\n        data[i] = [x, y];\r\n        labels[i] = 1;\r\n      }\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  circleData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let radius;\r\n    let offsetX = 0;\r\n    let offsetY = 0;\r\n    for (let i = 0; i < N; i++) {\r\n      if (i < N / 2) {\r\n        radius = random.randf(0.1, 2.5);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius + offsetX;\r\n        let y = Math.sin(angle) * radius + offsetY;\r\n        data[i] = [x, y];\r\n        labels[i] = 1;\r\n      } else {\r\n        radius = random.randf(2.25, 4);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius + offsetX;\r\n        let y = Math.sin(angle) * radius + offsetY;\r\n        data[i] = [x, y];\r\n        labels[i] = -1;\r\n      }\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  exclusiveOrData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let l = 3;\r\n    let offsetX = 0;\r\n    let offsetY = 0;\r\n    for (let i = 0; i < N; i++) {\r\n      if (i < N * 0.25) {\r\n        data[i] = [random.randf(0, l) + offsetX, random.randf(0, l) + offsetY];\r\n        labels[i] = 1;\r\n      } else if (i < N * 0.5) {\r\n        data[i] = [random.randf(0, l) + offsetX, random.randf(-l, 0) + offsetY];\r\n        labels[i] = -1;\r\n      } else if (i < N * 0.75) {\r\n        data[i] = [\r\n          random.randf(-l, 0) + offsetX,\r\n          random.randf(-l, 0) + offsetY\r\n        ];\r\n        labels[i] = 1;\r\n      } else {\r\n        data[i] = [random.randf(-l, 0) + offsetX, random.randf(0, l) + offsetY];\r\n        labels[i] = -1;\r\n      }\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  gaussianData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let radius;\r\n    let l = 3;\r\n    let offsetX = 0;\r\n    let offsetY = 0;\r\n    for (let i = 0; i < N; i++) {\r\n      if (i < N * 0.5) {\r\n        radius = random.randf(0, l - 1);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius + offsetX;\r\n        let y = Math.sin(angle) * radius + offsetY;\r\n        data[i] = [x + l / 4, y + l / 4];\r\n        labels[i] = 1;\r\n      } else {\r\n        radius = random.randf(0, l - 1);\r\n        let angle = Math.random() * Math.PI * 2;\r\n        let x = Math.cos(angle) * radius + offsetX;\r\n        let y = Math.sin(angle) * radius + offsetY;\r\n        data[i] = [x - l / 4, y - l / 4];\r\n        labels[i] = -1;\r\n      }\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  spiralData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let a = 0.1;\r\n    let b = 0.5;\r\n    let theta;\r\n    let perturbation = 0.2;\r\n    for (let i = 0; i < N / 2; i++) {\r\n      theta = Math.random() * Math.PI * 2;\r\n      let x = (a + b * theta) * Math.cos(theta);\r\n      x = x + random.randf(-perturbation, perturbation);\r\n      let y = (a + b * theta) * Math.sin(theta);\r\n      y = y + random.randf(-perturbation, perturbation);\r\n      data[i] = [x, y];\r\n      labels[i] = 1;\r\n    }\r\n    a = -a;\r\n    b = -b;\r\n    for (let i = N / 2; i < N; i++) {\r\n      theta = Math.random() * Math.PI * 2;\r\n      let x = (a + b * theta) * Math.cos(theta);\r\n      x = x + random.randf(-perturbation, perturbation);\r\n      let y = (a + b * theta) * Math.sin(theta);\r\n      y = y + random.randf(-perturbation, perturbation);\r\n      data[i] = [x, y];\r\n      labels[i] = -1;\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  stripesVData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let x, y;\r\n    for (let i = 0; i < N; i++) {\r\n      y = random.randf(-4, 4);\r\n      /*\r\n              if(i<N/6){\r\n                  x=randf(-3,-2);\r\n                  labels[i] = 1;\r\n              }\r\n              else if(i<N/3){\r\n                  x=randf(-2,-1);\r\n                  labels[i] = -1;\r\n              }\r\n              else if(i<N/2){\r\n                  x=randf(-1,0);\r\n                  labels[i] = 1;\r\n              }\r\n              else if(i<N*2/3){\r\n                  x=randf(0,1);\r\n                  labels[i] = -1;\r\n              }\r\n              else if(i<N*5/6){\r\n                  x=randf(1,2);\r\n                  labels[i] = 1;\r\n              }\r\n              else{\r\n                  x = randf(2,3);\r\n                  labels[i] = -1;\r\n              }*/\r\n      if (i < N / 4) {\r\n        x = random.randf(-3, -1.75);\r\n        labels[i] = 1;\r\n      } else if (i < N / 2) {\r\n        x = random.randf(-1.5, -0.25);\r\n        labels[i] = -1;\r\n      } else if (i < (N * 3) / 4) {\r\n        x = random.randf(0.25, 1.5);\r\n        labels[i] = 1;\r\n      } else {\r\n        x = random.randf(1.75, 3);\r\n        labels[i] = -1;\r\n      }\r\n      data[i] = [x, y];\r\n    }\r\n    return { data: data, labels: labels };\r\n  },\r\n  stripesHData: function(N) {\r\n    let data = new Array(N);\r\n    let labels = new Array(N);\r\n    let x, y;\r\n    for (let i = 0; i < N; i++) {\r\n      x = random.randf(-4, 4);\r\n      /*\r\n              if(i<N/6){\r\n                  x=randf(-3,-2);\r\n                  labels[i] = 1;\r\n              }\r\n              else if(i<N/3){\r\n                  x=randf(-2,-1);\r\n                  labels[i] = -1;\r\n              }\r\n              else if(i<N/2){\r\n                  x=randf(-1,0);\r\n                  labels[i] = 1;\r\n              }\r\n              else if(i<N*2/3){\r\n                  x=randf(0,1);\r\n                  labels[i] = -1;\r\n              }\r\n              else if(i<N*5/6){\r\n                  x=randf(1,2);\r\n                  labels[i] = 1;\r\n              }\r\n              else{\r\n                  x = randf(2,3);\r\n                  labels[i] = -1;\r\n              }*/\r\n      if (i < N / 4) {\r\n        y = random.randf(-3, -1.75);\r\n        labels[i] = 1;\r\n      } else if (i < N / 2) {\r\n        y = random.randf(-1.5, -0.25);\r\n        labels[i] = -1;\r\n      } else if (i < (N * 3) / 4) {\r\n        y = random.randf(0.25, 1.5);\r\n        labels[i] = 1;\r\n      } else {\r\n        y = random.randf(1.75, 3);\r\n        labels[i] = -1;\r\n      }\r\n      data[i] = [x, y];\r\n    }\r\n    return { data: data, labels: labels };\r\n  }\r\n};\r\n\r\nmodule.exports = dataset_generator;\r\n\n\n//# sourceURL=webpack:///./src/js/dataset.js?");

/***/ }),

/***/ "./src/js/drawer.js":
/*!**************************!*\
  !*** ./src/js/drawer.js ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/** YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name drawer.js\r\n * @description\r\n * function in charge of the drawing process. Keeps a local instace of one algorithm and draws based on his predictions.\r\n * @copyright Davide Ghiotto\r\n */\r\nconst input = __webpack_require__(/*! ./input.js */ \"./src/js/input.js\");\r\nconst getFunction = input.getFunction;\r\nconst boost = input.boost;\r\n\r\nlet id = 1;\r\nconst Drawer = function(algorithm, canvas, options) {\r\n  this.id = id++;\r\n  this.algorithm = algorithm;\r\n  this.canvas = canvas;\r\n  this.ctx = canvas.getContext(\"2d\");\r\n  if (this.ctx) {\r\n    canvas.addEventListener(\"click\", e => this.mouseClick(this.eventClick(e)));\r\n    this.options = options || {\r\n      margin: {\r\n        soft: true\r\n      },\r\n      data_radius: 6,\r\n      test_radius: 4\r\n    };\r\n    this.WIDTH = canvas.width;\r\n    this.HEIGHT = canvas.height;\r\n    this.options.ss = this.options.ss || 20;\r\n    this.options.density = this.options.density || 3;\r\n  } else console.warn(\"Could not get context from canvas: \" + canvas);\r\n};\r\n\r\nDrawer.prototype = {\r\n  getOptions: function() {\r\n    let options = {\r\n      group: \"drawer\" + this.id,\r\n      margin: {\r\n        group: \"margin\",\r\n        soft: {\r\n          id: \"soft\",\r\n          type: \"radio\",\r\n          name: \"margin\" + this.id,\r\n          value: \"soft\",\r\n          checked: this.options.margin.soft\r\n        },\r\n        hard: {\r\n          id: \"hard\",\r\n          type: \"radio\",\r\n          name: \"margin\" + this.id,\r\n          value: \"hard\",\r\n          checked: !this.options.margin.soft\r\n        }\r\n      },\r\n      data_radius: {\r\n        id: \"data_radius\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 10,\r\n        step: 1,\r\n        value: 6\r\n      },\r\n      test_radius: {\r\n        id: \"test_radius\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 10,\r\n        step: 1,\r\n        value: 4\r\n      },\r\n      ss: {\r\n        id: \"ss\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 50,\r\n        step: 1,\r\n        value: 20\r\n      },\r\n      density: {\r\n        id: \"density\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 10,\r\n        step: 1,\r\n        value: 3\r\n      },\r\n      boosted: {\r\n        id: \"boosted\",\r\n        type: \"checkbox\",\r\n        value: \"boosted\",\r\n        checked: this.options.boosted,\r\n        disabled: true\r\n      }\r\n    };\r\n    if (this.options.boosted) {\r\n      options.input_functions = {\r\n        group: \"input_functions\",\r\n        x2: {\r\n          id: \"x2\",\r\n          type: \"checkbox\",\r\n          value: \"x2\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        y2: {\r\n          id: \"y2\",\r\n          type: \"checkbox\",\r\n          value: \"y2\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        x3: {\r\n          id: \"x3\",\r\n          type: \"checkbox\",\r\n          value: \"x3\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        y3: {\r\n          id: \"y3\",\r\n          type: \"checkbox\",\r\n          value: \"y3\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        x2y2: {\r\n          id: \"x2y2\",\r\n          type: \"checkbox\",\r\n          value: \"x2y2\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        x2_y2: {\r\n          id: \"x2_y2\",\r\n          type: \"checkbox\",\r\n          value: \"x2_y2\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        xy: {\r\n          id: \"xy\",\r\n          type: \"checkbox\",\r\n          value: \"xy\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        sinx: {\r\n          id: \"sinx\",\r\n          type: \"checkbox\",\r\n          value: \"sinx\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        siny: {\r\n          id: \"siny\",\r\n          type: \"checkbox\",\r\n          value: \"siny\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        cosx: {\r\n          id: \"cosx\",\r\n          type: \"checkbox\",\r\n          value: \"cosx\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        cosy: {\r\n          id: \"cosy\",\r\n          type: \"checkbox\",\r\n          value: \"cosy\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        sinxcosy: {\r\n          id: \"sinxcosy\",\r\n          type: \"checkbox\",\r\n          value: \"sinxcosy\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        sinycosx: {\r\n          id: \"sinycosx\",\r\n          type: \"checkbox\",\r\n          value: \"sinycosx\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        sinxcosydot: {\r\n          id: \"sinxcosydot\",\r\n          type: \"checkbox\",\r\n          value: \"sinxcosydot\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        },\r\n        sinycosxdot: {\r\n          id: \"sinycosxdot\",\r\n          type: \"checkbox\",\r\n          value: \"sinycosxdot\",\r\n          name: \"input_functions\" + this.id,\r\n          checked: false\r\n        }\r\n      };\r\n    }\r\n    return options;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options || {};\r\n  },\r\n  getBoosting: function() {\r\n    if (this.options.boosted) {\r\n      let input_functions = [];\r\n      for (let i in this.options.input_functions)\r\n        if (this.options.input_functions[i])\r\n          input_functions.push(getFunction(i));\r\n      return input_functions;\r\n    } else return [];\r\n  },\r\n  setManager: function(manager) {\r\n    this.manager = manager;\r\n  },\r\n  setAlgorithm: function(algorithm) {\r\n    this.algorithm = algorithm;\r\n  },\r\n  getAlgorithm: function() {\r\n    return this.algorithm;\r\n  },\r\n  draw: function(points, labels) {\r\n    //clear\r\n    this.ctx.clearRect(0, 0, this.WIDTH, this.HEIGHT);\r\n    //draw grid\r\n    this.drawGrid();\r\n    //draw axes\r\n    this.drawAxes();\r\n    //draw data points\r\n    this.drawDataPoints(points, labels);\r\n  },\r\n  drawGrid: function() {\r\n    let boosting = [];\r\n    if (this.options.boosted) {\r\n      boosting = this.getBoosting();\r\n    }\r\n    for (let x = 0.0; x <= this.WIDTH; x += this.options.density) {\r\n      for (let y = 0.0; y <= this.HEIGHT; y += this.options.density) {\r\n        let X = (x - this.WIDTH / 2) / this.options.ss;\r\n        let Y = (y - this.HEIGHT / 2) / this.options.ss;\r\n        let point = boost(boosting, [X, Y]);\r\n        let predicted_class = this.algorithm.predictClass(point);\r\n        let predicted_value = 0;\r\n        if (this.options.margin.soft)\r\n          predicted_value = this.algorithm.predict(point);\r\n        else predicted_value = predicted_class;\r\n\r\n        this.ctx.fillStyle = getColor(predicted_value, predicted_class);\r\n        this.ctx.fillRect(\r\n          x - this.options.density / 2 - 1,\r\n          y - this.options.density - 1,\r\n          this.options.density + 2,\r\n          this.options.density + 2\r\n        );\r\n      }\r\n    }\r\n  },\r\n  drawAxes: function() {\r\n    this.ctx.beginPath();\r\n    this.ctx.strokeStyle = \"rgb(50,50,50)\";\r\n    this.ctx.lineWidth = 1;\r\n    this.ctx.moveTo(0, this.HEIGHT / 2);\r\n    this.ctx.lineTo(this.WIDTH, this.HEIGHT / 2);\r\n    this.ctx.moveTo(this.WIDTH / 2, 0);\r\n    this.ctx.lineTo(this.WIDTH / 2, this.HEIGHT);\r\n    this.ctx.stroke();\r\n  },\r\n  drawDataPoints: function(points, labels) {\r\n    let radius = this.options.data_radius || 6;\r\n    let boosting = [];\r\n    if (this.options.boosted) {\r\n      boosting = this.getBoosting();\r\n    }\r\n    for (let i = 0; i < points.length; i++) {\r\n      let prediction = this.algorithm.predictClass(boost(boosting, points[i]));\r\n      this.ctx.fillStyle = getPointColor(prediction, labels[i]);\r\n      this.drawCircle(\r\n        points[i][0] * this.options.ss + this.WIDTH / 2,\r\n        points[i][1] * this.options.ss + this.HEIGHT / 2,\r\n        radius\r\n      );\r\n    }\r\n  },\r\n  drawTestPoints: function(points, labels) {\r\n    let radius = this.options.test_radius || 4;\r\n    for (let i = 0; i < points.length; i++) {\r\n      let prediction = this.algorithm.predictClass(boost(points[i]));\r\n      this.ctx.fillStyle = getPointColor(prediction, labels[i]);\r\n      this.drawCircle(\r\n        points[i][0] * this.options.ss + this.WIDTH / 2,\r\n        points[i][1] * this.options.ss + this.HEIGHT / 2,\r\n        radius\r\n      );\r\n    }\r\n  },\r\n  drawCircle: function(x, y, r) {\r\n    this.ctx.beginPath();\r\n    this.ctx.arc(x, y, r, 0, Math.PI * 2, true);\r\n    this.ctx.closePath();\r\n    this.ctx.stroke();\r\n    this.ctx.fill();\r\n  },\r\n  mouseClick: function({ x, y, shiftPressed, ctrlPressed }) {\r\n    let point = [\r\n      (x - this.WIDTH / 2) / this.options.ss,\r\n      (y - this.HEIGHT / 2) / this.options.ss\r\n    ];\r\n    if (ctrlPressed) this.manager.removePoint(point);\r\n    else {\r\n      let label = shiftPressed ? 1 : -1;\r\n      this.manager.addPoint(point, label);\r\n    }\r\n    this.manager.notifyAll();\r\n  },\r\n  eventClick: function(e) {\r\n    //get position of cursor relative to top left of canvas\r\n    let x = 0;\r\n    let y = 0;\r\n    if (e.pageX || e.pageY) {\r\n      x = e.pageX;\r\n      y = e.pageY;\r\n    }\r\n    x -= this.canvas.offsetLeft;\r\n    y -= this.canvas.offsetTop;\r\n    return { x: x, y: y, shiftPressed: e.shiftKey, ctrlPressed: e.ctrlKey };\r\n  }\r\n};\r\n\r\nfunction getPointColor(predicted, real) {\r\n  if (predicted * real > 0) {\r\n    if (predicted > 0) return \"rgb(150,250,150)\";\r\n    else return \"rgb(250,150,150)\";\r\n  } else {\r\n    if (predicted > 0) return \"rgb(105,147,250)\";\r\n    else return \"rgb(240,226,63)\";\r\n  }\r\n}\r\n\r\nfunction getColor(predicted, real) {\r\n  let ri, gi;\r\n  if (predicted < 0) {\r\n    // less red 250-150\r\n    ri = 150 - 100 * predicted; //with value = -1 ===> ri = 250\r\n    gi = 250 + 100 * predicted; //with value = -1 ===> gi = 150\r\n  } else {\r\n    //less green 150-250\r\n    ri = 250 - 100 * predicted; //with value = 1 ===> ri = 150\r\n    gi = 150 + 100 * predicted; //with value = 1 ===> gi = 250\r\n  }\r\n  if (real > 0) gi += 5;\r\n  else ri += 35;\r\n  return \"rgb(\" + Math.floor(ri) + \",\" + Math.floor(gi) + \",150)\";\r\n}\r\n\r\nmodule.exports = Drawer;\r\n\n\n//# sourceURL=webpack:///./src/js/drawer.js?");

/***/ }),

/***/ "./src/js/index.js":
/*!*************************!*\
  !*** ./src/js/index.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const LogisticRegression = __webpack_require__(/*! ./logreg/logreg.js */ \"./src/js/logreg/logreg.js\").LogisticRegression;\r\nconst SVM = __webpack_require__(/*! ./svm/svm.js */ \"./src/js/svm/svm.js\");\r\nconst KNN = __webpack_require__(/*! ./knn/knn.js */ \"./src/js/knn/knn.js\");\r\nconst RBF = __webpack_require__(/*! ./rbf/rbf.js */ \"./src/js/rbf/rbf.js\");\r\nconst RandomForest = __webpack_require__(/*! ./randf/randf.js */ \"./src/js/randf/randf.js\");\r\nconst Drawer = __webpack_require__(/*! ./drawer.js */ \"./src/js/drawer.js\");\r\nconst NeuralNet = __webpack_require__(/*! ./nn/nn.js */ \"./src/js/nn/nn.js\");\r\nconst Manager = __webpack_require__(/*! ./manager.js */ \"./src/js/manager.js\");\r\nconst UI = __webpack_require__(/*! ./ui.js */ \"./src/js/ui.js\");\r\nconst dataset_generator = __webpack_require__(/*! ./dataset.js */ \"./src/js/dataset.js\");\r\n\r\nmodule.exports = {\r\n  LOGREG: LogisticRegression,\r\n  SVM: SVM,\r\n  KNN: KNN,\r\n  RBF: RBF,\r\n  RANDF: RandomForest,\r\n  NN: NeuralNet,\r\n  Manager: Manager,\r\n  UI: UI,\r\n  Drawer: Drawer,\r\n  dataset_generator: dataset_generator\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/index.js?");

/***/ }),

/***/ "./src/js/input.js":
/*!*************************!*\
  !*** ./src/js/input.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/** YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name input.js\r\n * @description\r\n * A list of input transformation function, also called \"boosting\" functions.\r\n * They receive an array and then return a boosted version based on the function they use.\r\n * @copyright Davide Ghiotto\r\n */\r\n\r\nconst copyArray = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\").array.copyArray;\r\n\r\nfunction fx2(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[0], 2));\r\n  return res;\r\n}\r\nfunction fy2(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[1], 2));\r\n  return res;\r\n}\r\nfunction fx3(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[0], 3));\r\n  return res;\r\n}\r\nfunction fy3(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[1], 3));\r\n  return res;\r\n}\r\nfunction fx2y2(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[0], 2) + Math.pow(v[1], 2));\r\n  return res;\r\n}\r\nfunction fx2_y2(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.pow(v[0], 2) - Math.pow(v[1], 2));\r\n  return res;\r\n}\r\nfunction fxy(v) {\r\n  let res = copyArray(v);\r\n  res.push(v[0] * v[1]);\r\n  return res;\r\n}\r\nfunction fsinx(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[0]));\r\n  return res;\r\n}\r\nfunction fsiny(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[1]));\r\n  return res;\r\n}\r\nfunction fcosx(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.cos(v[0]));\r\n  return res;\r\n}\r\nfunction fcosy(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.cos(v[1]));\r\n  return res;\r\n}\r\nfunction fsinxcosy(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[0]) + Math.cos(v[1]));\r\n  return res;\r\n}\r\nfunction fsinycosx(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[1]) + Math.cos(v[0]));\r\n  return res;\r\n}\r\nfunction fsinxcosydot(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[0]) * Math.cos(v[1]));\r\n  return res;\r\n}\r\nfunction fsinycosxdot(v) {\r\n  let res = copyArray(v);\r\n  res.push(Math.sin(v[1]) * Math.cos(v[0]));\r\n  return res;\r\n}\r\n\r\nfunction boost(input_boosting, point) {\r\n  if (input_boosting.length > 0) {\r\n    let boosted = copyArray(point);\r\n    for (let i = 0; i < input_boosting.length; i++) {\r\n      boosted = input_boosting[i](boosted);\r\n    }\r\n    return boosted;\r\n  } else return point;\r\n}\r\n\r\nfunction getFunction(id) {\r\n  if (id === \"x2\") return fx2;\r\n  else if (id === \"y2\") return fy2;\r\n  else if (id === \"x3\") return fx3;\r\n  else if (id === \"y3\") return fy3;\r\n  else if (id === \"x2y2\") return fx2y2;\r\n  else if (id === \"x2_y2\") return fx2_y2;\r\n  else if (id === \"xy\") return fxy;\r\n  else if (id === \"sinx\") return fsinx;\r\n  else if (id === \"siny\") return fsiny;\r\n  else if (id === \"cosx\") return fcosx;\r\n  else if (id === \"cosy\") return fcosy;\r\n  else if (id === \"sinxcosy\") return fsinxcosy;\r\n  else if (id === \"sinycosx\") return fsinycosx;\r\n  else if (id === \"sinxcosydot\") return fsinxcosydot;\r\n  else if (id === \"sinycosxdot\") return fsinycosxdot;\r\n}\r\n\r\nmodule.exports = {\r\n  boost: boost,\r\n  getFunction: getFunction\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/input.js?");

/***/ }),

/***/ "./src/js/knn/distances/distances.js":
/*!*******************************************!*\
  !*** ./src/js/knn/distances/distances.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/**\r\n *\r\n * @description\r\n * Class used to handle distances functions\r\n * @example\r\n * //new instance\r\n * let distances = new Distances();\r\n * //define two points\r\n * let point1 = [1,3];\r\n * let point2 = [4,-2];\r\n * //minkowski distance from two points\r\n * let minkowski_distance = distances.minkowski(point1,point2);\r\n * //chebyshev distance from two points\r\n * let chebyshev_distance = distances.chebyshev(point1,point2);\r\n * //mahalanobis distance from two points\r\n * let mahalanobis_distance = distances.mahalanobis(point1,point2);\r\n * //setting the grade for minkowski\r\n * distances.setMinkowskiDegree(2);\r\n */\r\n\r\nconst utils = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\");\r\n\r\nconst Distances = function() {\r\n  this.p = 1;\r\n  this.data = [];\r\n  this.variance = 0;\r\n  this.default = function() {};\r\n};\r\n\r\nDistances.prototype = {\r\n  /**\r\n   * Sets the dataset and calculate the variance\r\n   * @param data {data} dataset to be used for the distances calculations\r\n   */\r\n  setDataSet: function(data) {\r\n    this.data = data;\r\n    this.variance = utils.statistics.variance(data);\r\n  },\r\n\r\n  /**\r\n   * Set the default function for the distance calculation\r\n   * @param {String} algorithm\r\n   */\r\n  setDefault: function(algorithm) {\r\n    if (algorithm === \"minkowski\") this.default = this.minkowski;\r\n    else if (algorithm === \"chebyshev\") this.default = this.chebyshev;\r\n    else if (algorithm === \"mahalanobis\") this.default = this.mahalanobis;\r\n    else this.default = this.minkowski;\r\n  },\r\n\r\n  /**\r\n   * Returns the distance between two points using the default algorithm\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} distance\r\n   */\r\n  of: function(point1, point2) {\r\n    try {\r\n      return this.default(point1, point2);\r\n    } catch (e) {\r\n      console.warn(e);\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Sets the degree of the minkowski distance\r\n   * @param p {Number} the degree for minkowski distance\r\n   */\r\n  setMinkowskiDegree: function(p) {\r\n    this.p = p || this.p;\r\n    if (this.p < 1) this.p = 1;\r\n  },\r\n\r\n  /**\r\n   * Returns the minkowski distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} minkowski distance\r\n   */\r\n  minkowski: function(point1, point2) {\r\n    if (point1.length !== point2.length) {\r\n      console.warn(\"point of different lengths\");\r\n      return;\r\n    }\r\n    let sum = 0;\r\n    for (let i = 0; i < point1.length; i++)\r\n      sum += Math.pow(Math.abs(point1[i] - point2[i]), this.p);\r\n    return Math.pow(sum, 1 / this.p);\r\n  },\r\n\r\n  /**\r\n   * Returns the chebyshev distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} chebyshev distance between the two points\r\n   */\r\n  chebyshev: function(point1, point2) {\r\n    let value;\r\n    let max = 0;\r\n    for (let i = 0; i < point1.length; i++) {\r\n      value = Math.abs(point2[i] - point1[i]);\r\n      if (value > max) max = value;\r\n    }\r\n    return max;\r\n  },\r\n\r\n  /**\r\n   * Returns the mahalanobis distance between two points\r\n   * @param point1 {point} first point\r\n   * @param point2 {point} second point\r\n   * @returns {number} mahalanobis distance between the two points\r\n   */\r\n  mahalanobis: function(point1, point2) {\r\n    if (this.data.length === 0) throw \"no data\";\r\n    let sum = 0;\r\n    for (let i = 0; i < point1.length; i++)\r\n      sum += Math.pow(point1[i] - point2[i], 2) / Math.pow(this.variance[i], 2);\r\n    return Math.sqrt(sum);\r\n  }\r\n};\r\n\r\nmodule.exports = Distances;\r\n\n\n//# sourceURL=webpack:///./src/js/knn/distances/distances.js?");

/***/ }),

/***/ "./src/js/knn/knn.js":
/*!***************************!*\
  !*** ./src/js/knn/knn.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const Distances = __webpack_require__(/*! ./distances/distances.js */ \"./src/js/knn/distances/distances.js\");\r\nconst KNN = function() {};\r\nKNN.prototype = {\r\n  train: function(data, labels) {\r\n    this.data = data;\r\n    this.labels = labels;\r\n    this.options = this.options || {};\r\n    let k = this.options.k || 1;\r\n    if (k < 1) k = 1;\r\n    if (k > this.data.length) {\r\n      console.warn(\r\n        \"need more data: KNN with K: \" + k + \" and #data: \" + this.data.length\r\n      );\r\n      return 0;\r\n    }\r\n    this.k = k;\r\n    this.distances = new Distances();\r\n    this.distances.setDataSet(data);\r\n    let distance;\r\n    for (let d in this.options.distance) {\r\n      if (this.options.distance[d]) distance = d;\r\n    }\r\n    this.distances.setDefault(distance);\r\n    if (distance === \"minkowski\") {\r\n      let p = this.options.p || 1;\r\n      this.distances.setMinkowskiDegree(p);\r\n    }\r\n  },\r\n  predict: function(point) {\r\n    if (!this.k) console.warn(\"k not defined\");\r\n    else return (this.knn(point, this.k) + 1) / 2;\r\n  },\r\n  predictClass: function(point) {\r\n    if (!this.k) console.warn(\"k not defined\");\r\n    else return this.knn(point, this.k) > 0 ? 1 : -1;\r\n  },\r\n  knn: function(point, k) {\r\n    let nearest = new Array(k);\r\n    for (let i = 0; i < k; i++) {\r\n      nearest[i] = {};\r\n      nearest[i].distance = this.distances.of(point, this.data[i]);\r\n      nearest[i].label = this.labels[i];\r\n    }\r\n\r\n    nearest.sort(function(a, b) {\r\n      return b.distance - a.distance;\r\n    }); //ordino decrescente\r\n\r\n    let d = 0;\r\n\r\n    for (let i = k; i < this.data.length; i++) {\r\n      d = this.distances.of(point, this.data[i]);\r\n      if (nearest[0].distance > d) {\r\n        //se è più distante il più distante dei nearest, aggiorno la lista\r\n        nearest[0].distance = d;\r\n        nearest[0].label = this.labels[i];\r\n        nearest.sort((a, b) => b.distance - a.distance); //ordino decrescente\r\n      }\r\n    }\r\n\r\n    let c = 0;\r\n    let class1 = 0;\r\n    let class2 = 0;\r\n    for (let i = 0; i < k; i++) {\r\n      c += nearest[i].label;\r\n      if (nearest[i].label === 1) class2++;\r\n      else class1++;\r\n    }\r\n    if (c === 0) return 0;\r\n    if (c > 0) return class2 / k;\r\n    //greenish\r\n    else return -class1 / k; //reddish\r\n  },\r\n  getOptions: function() {\r\n    let options = {\r\n      group: \"knn\",\r\n      k: {\r\n        id: \"k\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 20,\r\n        step: 1,\r\n        value: 3\r\n      },\r\n      p: {\r\n        id: \"p\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 10,\r\n        step: 1,\r\n        value: 2\r\n      },\r\n      distance: {\r\n        group: \"distance\",\r\n        minkowski: {\r\n          id: \"minkowski\",\r\n          type: \"radio\",\r\n          name: \"distances\",\r\n          value: \"minkowski\",\r\n          checked: true\r\n        },\r\n        chebyshev: {\r\n          id: \"chebyshev\",\r\n          type: \"radio\",\r\n          name: \"distances\",\r\n          value: \"chebyshev\"\r\n        },\r\n        mahalanobis: {\r\n          id: \"mahalanobis\",\r\n          type: \"radio\",\r\n          name: \"distances\",\r\n          value: \"mahalanobis\"\r\n        }\r\n      }\r\n    };\r\n    return options;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options;\r\n  }\r\n};\r\n\r\nmodule.exports = KNN;\r\n\n\n//# sourceURL=webpack:///./src/js/knn/knn.js?");

/***/ }),

/***/ "./src/js/logreg/logreg.js":
/*!*********************************!*\
  !*** ./src/js/logreg/logreg.js ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("const LinearRegression = function(config) {\r\n  config = config || {};\r\n\r\n  if (!config.iterations) {\r\n    config.iterations = 1000;\r\n  }\r\n  if (!config.alpha) {\r\n    config.alpha = 0.001;\r\n  }\r\n  if (!config.lambda) {\r\n    config.lambda = 0.0;\r\n  }\r\n  if (!config.trace) {\r\n    config.trace = false;\r\n  }\r\n\r\n  this.iterations = config.iterations;\r\n  this.alpha = config.alpha;\r\n  this.lambda = config.lambda;\r\n  this.trace = config.trace;\r\n};\r\n\r\nLinearRegression.prototype.fit = function(data) {\r\n  let N = data.length,\r\n    X = [],\r\n    Y = [];\r\n  this.dim = data[0].length;\r\n\r\n  for (let i = 0; i < N; ++i) {\r\n    let row = data[i];\r\n    let x_i = [];\r\n    let y_i = row[row.length - 1];\r\n    x_i.push(1.0);\r\n    for (let j = 0; j < row.length - 1; ++j) {\r\n      x_i.push(row[j]);\r\n    }\r\n    Y.push(y_i);\r\n    X.push(x_i);\r\n  }\r\n\r\n  this.theta = [];\r\n\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    this.theta.push(0.0);\r\n  }\r\n\r\n  for (let k = 0; k < this.iterations; ++k) {\r\n    let Vx = this.grad(X, Y, this.theta);\r\n\r\n    for (let d = 0; d < this.dim; ++d) {\r\n      this.theta[d] = this.theta[d] - this.alpha * Vx[d];\r\n    }\r\n\r\n    if (this.trace) {\r\n      console.log(\r\n        \"cost at iteration \" + k + \": \" + this.cost(X, Y, this.theta)\r\n      );\r\n    }\r\n  }\r\n\r\n  return {\r\n    theta: this.theta,\r\n    dim: this.dim,\r\n    cost: this.cost(X, Y, this.theta),\r\n    config: {\r\n      alpha: this.alpha,\r\n      lambda: this.lambda,\r\n      iterations: this.iterations\r\n    }\r\n  };\r\n};\r\n\r\nLinearRegression.prototype.grad = function(X, Y, theta) {\r\n  let N = X.length;\r\n\r\n  let Vtheta = [];\r\n\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    let g = 0;\r\n    for (let i = 0; i < N; ++i) {\r\n      let x_i = X[i];\r\n      let y_i = Y[i];\r\n\r\n      let predicted = this.h(x_i, theta);\r\n\r\n      g += (predicted - y_i) * x_i[d];\r\n    }\r\n\r\n    g = (g + this.lambda * theta[d]) / N;\r\n\r\n    Vtheta.push(g);\r\n  }\r\n\r\n  return Vtheta;\r\n};\r\n\r\nLinearRegression.prototype.h = function(x_i, theta) {\r\n  let predicted = 0.0;\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    predicted += x_i[d] * theta[d];\r\n  }\r\n  return predicted;\r\n};\r\n\r\nLinearRegression.prototype.cost = function(X, Y, theta) {\r\n  let N = X.length;\r\n  let cost = 0;\r\n  for (let i = 0; i < N; ++i) {\r\n    let x_i = X[i];\r\n    let predicted = this.h(x_i, theta);\r\n    cost += (predicted - Y[i]) * (predicted - Y[i]);\r\n  }\r\n\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    cost += this.lambda * theta[d] * theta[d];\r\n  }\r\n\r\n  return cost / (2.0 * N);\r\n};\r\n\r\nLinearRegression.prototype.transform = function(x) {\r\n  if (x[0].length) {\r\n    // x is a matrix\r\n    let predicted_array = [];\r\n    for (let i = 0; i < x.length; ++i) {\r\n      let predicted = this.transform(x[i]);\r\n      predicted_array.push(predicted);\r\n    }\r\n    return predicted_array;\r\n  }\r\n\r\n  // x is a row vector\r\n  let x_i = [];\r\n  x_i.push(1.0);\r\n  for (let j = 0; j < x.length; ++j) {\r\n    x_i.push(x[j]);\r\n  }\r\n  return this.h(x_i, this.theta);\r\n};\r\n\r\n//_________________Logistic Regression__________________\r\n\r\nconst LogisticRegression = function() {};\r\n\r\nLogisticRegression.prototype.getOptions = function() {\r\n  let options = {\r\n    group: \"logistic regression\",\r\n    alpha: {\r\n      id: \"alpha\",\r\n      type: \"range\",\r\n      min: 0,\r\n      max: 0.01,\r\n      step: 0.001,\r\n      value: this.alpha\r\n    },\r\n    iteration: {\r\n      id: \"iterations\",\r\n      type: \"range\",\r\n      min: 10,\r\n      max: 1000,\r\n      step: 10,\r\n      value: this.iterations\r\n    },\r\n    lamda: {\r\n      id: \"lamda\",\r\n      type: \"range\",\r\n      min: 0,\r\n      max: 1,\r\n      step: 0.1,\r\n      value: this.lambda\r\n    }\r\n  };\r\n  return options;\r\n};\r\n\r\nLogisticRegression.prototype.setOptions = function(options) {\r\n  this.options = options;\r\n};\r\n\r\nLogisticRegression.prototype.train = function(data, labels) {\r\n  let config = this.options || {};\r\n  if (!config.alpha) {\r\n    config.alpha = 0.001;\r\n  }\r\n  if (!config.iterations) {\r\n    config.iterations = 100;\r\n  }\r\n  if (!config.lambda) {\r\n    config.lambda = 0;\r\n  }\r\n  this.alpha = config.alpha;\r\n  this.lambda = config.lambda;\r\n  this.iterations = config.iterations;\r\n\r\n  let data_labels = [];\r\n  for (let i = 0; i < data.length; i++) {\r\n    data_labels.push(data[i].concat(labels[i]));\r\n  }\r\n  this.fit(data_labels);\r\n};\r\n\r\nLogisticRegression.prototype.fit = function(data) {\r\n  this.dim = data[0].length;\r\n  let N = data.length;\r\n\r\n  let X = [];\r\n  let Y = [];\r\n  for (let i = 0; i < N; ++i) {\r\n    let row = data[i];\r\n    let x_i = [];\r\n    let y_i = row[row.length - 1];\r\n    x_i.push(1.0);\r\n    for (let j = 0; j < row.length - 1; ++j) {\r\n      x_i.push(row[j]);\r\n    }\r\n    X.push(x_i);\r\n    Y.push(y_i);\r\n  }\r\n\r\n  this.theta = [];\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    this.theta.push(0.0);\r\n  }\r\n\r\n  for (let iter = 0; iter < this.iterations; ++iter) {\r\n    let theta_delta = this.grad(X, Y, this.theta);\r\n    for (let d = 0; d < this.dim; ++d) {\r\n      this.theta[d] = this.theta[d] - this.alpha * theta_delta[d];\r\n    }\r\n  }\r\n\r\n  this.threshold = this.computeThreshold(X, Y);\r\n\r\n  return {\r\n    theta: this.theta,\r\n    threshold: this.threshold,\r\n    cost: this.cost(X, Y, this.theta),\r\n    config: {\r\n      alpha: this.alpha,\r\n      lambda: this.lambda,\r\n      iterations: this.iterations\r\n    }\r\n  };\r\n};\r\n\r\nLogisticRegression.prototype.computeThreshold = function(X, Y) {\r\n  let threshold = 1.0,\r\n    N = X.length;\r\n\r\n  for (let i = 0; i < N; ++i) {\r\n    let prob = this.transform(X[i]);\r\n    if (Y[i] === 1 && threshold > prob) {\r\n      threshold = prob;\r\n    }\r\n  }\r\n\r\n  return threshold;\r\n};\r\n\r\nLogisticRegression.prototype.grad = function(X, Y, theta) {\r\n  let N = X.length;\r\n  let Vx = [];\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    let sum = 0.0;\r\n    for (let i = 0; i < N; ++i) {\r\n      let x_i = X[i];\r\n      let predicted = this.h(x_i, theta);\r\n      sum += ((predicted - Y[i]) * x_i[d] + this.lambda * theta[d]) / N;\r\n    }\r\n    Vx.push(sum);\r\n  }\r\n\r\n  return Vx;\r\n};\r\n\r\nLogisticRegression.prototype.h = function(x_i, theta) {\r\n  let gx = 0.0;\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    gx += theta[d] * x_i[d];\r\n  }\r\n  return 1.0 / (1.0 + Math.exp(-gx));\r\n};\r\n\r\nLogisticRegression.prototype.transform = function(x) {\r\n  if (x[0].length) {\r\n    // x is a matrix\r\n    let predicted_array = [];\r\n    for (let i = 0; i < x.length; ++i) {\r\n      let predicted = this.transform(x[i]);\r\n      predicted_array.push(predicted);\r\n    }\r\n    return predicted_array;\r\n  }\r\n\r\n  let x_i = [];\r\n  x_i.push(1.0);\r\n  for (let j = 0; j < x.length; ++j) {\r\n    x_i.push(x[j]);\r\n  }\r\n  return this.h(x_i, this.theta);\r\n};\r\n\r\nLogisticRegression.prototype.predict = function(x) {\r\n  let gx = this.theta[0];\r\n  for (let d = 0; d < x.length; ++d) {\r\n    gx += this.theta[d + 1] * x[d];\r\n  }\r\n  return 1 / (1.0 + Math.exp(-gx));\r\n};\r\n\r\nLogisticRegression.prototype.predictClass = function(x) {\r\n  return this.predict(x) > 0.5 ? 1 : -1;\r\n};\r\n\r\n// LogisticRegression.prototype.setOptions = function(configurations) {\r\n//   let config_update = configurations || {};\r\n//   if (!config_update.alpha) {\r\n//     config_update.alpha = 0.001;\r\n//   }\r\n//   if (!config_update.iterations) {\r\n//     config_update.iterations = 100;\r\n//   }\r\n//   if (!config_update.lambda) {\r\n//     config_update.lambda = 0;\r\n//   }\r\n//   this.alpha = config_update.alpha;\r\n//   this.lambda = config_update.lambda;\r\n//   this.iterations = config_update.iterations;\r\n// };\r\n\r\nLogisticRegression.prototype.cost = function(X, Y, theta) {\r\n  let N = X.length;\r\n  let sum = 0;\r\n  for (let i = 0; i < N; ++i) {\r\n    let y_i = Y[i];\r\n    let x_i = X[i];\r\n    sum +=\r\n      -(\r\n        y_i * Math.log(this.h(x_i, theta)) +\r\n        (1 - y_i) * Math.log(1 - this.h(x_i, theta))\r\n      ) / N;\r\n  }\r\n\r\n  for (let d = 0; d < this.dim; ++d) {\r\n    sum += (this.lambda * theta[d] * theta[d]) / (2.0 * N);\r\n  }\r\n  return sum;\r\n};\r\n\r\n//_______________MultiClassLogistic______________-\r\n\r\nconst MultiClassLogistic = function(import_config) {\r\n  let config = import_config || {};\r\n  if (!config.alpha) {\r\n    config.alpha = 0.001;\r\n  }\r\n  if (!config.iterations) {\r\n    config.iterations = 100;\r\n  }\r\n  if (!config.lambda) {\r\n    config.lambda = 0;\r\n  }\r\n  this.alpha = config.alpha;\r\n  this.lambda = config.lambda;\r\n  this.iterations = config.iterations;\r\n};\r\n\r\nMultiClassLogistic.prototype.fit = function(data, classes) {\r\n  this.dim = data[0].length;\r\n  let N = data.length;\r\n\r\n  if (!classes) {\r\n    classes = [];\r\n    for (let i = 0; i < N; ++i) {\r\n      let found = false;\r\n      let label = data[i][this.dim - 1];\r\n      for (let j = 0; j < classes.length; ++j) {\r\n        if (label === classes[j]) {\r\n          found = true;\r\n          break;\r\n        }\r\n      }\r\n      if (!found) {\r\n        classes.push(label);\r\n      }\r\n    }\r\n  }\r\n\r\n  this.classes = classes;\r\n\r\n  this.logistics = {};\r\n  let result = {};\r\n  for (let k = 0; k < this.classes.length; ++k) {\r\n    let c = this.classes[k];\r\n    this.logistics[c] = new jsr.LogisticRegression({\r\n      alpha: this.alpha,\r\n      lambda: this.lambda,\r\n      iterations: this.iterations\r\n    });\r\n    let data_c = [];\r\n    for (let i = 0; i < N; ++i) {\r\n      let row = [];\r\n      for (let j = 0; j < this.dim - 1; ++j) {\r\n        row.push(data[i][j]);\r\n      }\r\n      row.push(data[i][this.dim - 1] === c ? 1 : 0);\r\n      data_c.push(row);\r\n    }\r\n    result[c] = this.logistics[c].fit(data_c);\r\n  }\r\n  return result;\r\n};\r\n\r\nMultiClassLogistic.prototype.transform = function(x) {\r\n  if (x[0].length) {\r\n    // x is a matrix\r\n    let predicted_array = [];\r\n    for (let i = 0; i < x.length; ++i) {\r\n      let predicted = this.transform(x[i]);\r\n      predicted_array.push(predicted);\r\n    }\r\n    return predicted_array;\r\n  }\r\n\r\n  let max_prob = 0.0;\r\n  let best_c = \"\";\r\n  for (let k = 0; k < this.classes.length; ++k) {\r\n    let c = this.classes[k];\r\n    let prob_c = this.logistics[c].transform(x);\r\n    if (max_prob < prob_c) {\r\n      max_prob = prob_c;\r\n      best_c = c;\r\n    }\r\n  }\r\n\r\n  return best_c;\r\n};\r\n\r\nmodule.exports = {\r\n  LinearRegression: LinearRegression,\r\n  LogisticRegression: LogisticRegression\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/logreg/logreg.js?");

/***/ }),

/***/ "./src/js/manager.js":
/*!***************************!*\
  !*** ./src/js/manager.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/** YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name manager.js\r\n * @description\r\n * Manager of the data flow between multiple algorithms.\r\n * This function was built with the \"observer\" pattern in mind:\r\n * all the drawers that subscribe to the manager receive themselves a manager instance.\r\n * Manager will notify all the subscribers (drawers) whenever a drawer call for an update.\r\n * @copyright Davide Ghiotto\r\n */\r\nconst copyArray = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\").array.copyArray;\r\nconst boost = __webpack_require__(/*! ./input.js */ \"./src/js/input.js\").boost;\r\nconst Manager = function() {\r\n  this.data = [];\r\n  this.labels = [];\r\n  this.drawers = [];\r\n};\r\nManager.prototype = {\r\n  subscribe: function(drawer) {\r\n    drawer.setManager(this);\r\n    this.drawers.push(drawer);\r\n  },\r\n  notifyAll: function() {\r\n    this.drawers.forEach(drawer => this.notify(drawer));\r\n  },\r\n  notify: function(drawer) {\r\n    let input_boosting = drawer.getBoosting();\r\n    if (input_boosting.length > 0) {\r\n      let boosted = copyArray(this.data);\r\n      for (let i = 0; i < boosted.length; i++)\r\n        boosted[i] = boost(input_boosting, this.data[i]);\r\n      drawer.getAlgorithm().train(boosted, this.labels);\r\n      drawer.draw(boosted, this.labels);\r\n    } else {\r\n      drawer.getAlgorithm().train(this.data, this.labels);\r\n      drawer.draw(this.data, this.labels);\r\n    }\r\n  },\r\n  setDataSet: function(data, labels) {\r\n    this.data = data;\r\n    this.labels = labels;\r\n  },\r\n  addPoint: function(point, label) {\r\n    this.data.push(point);\r\n    this.labels.push(label);\r\n  },\r\n  removePoint: function(point) {\r\n    let index = 0;\r\n    let distanceFrom = ([x1, y1], [x2, y2]) =>\r\n      Math.sqrt(Math.pow(x1 - x2, 2) + Math.pow(y1 - y2, 2));\r\n    let min = distanceFrom(this.data[0], point);\r\n    for (let i = 0; i < this.data.length; i++) {\r\n      let d = distanceFrom(this.data[i], point);\r\n      if (d < min) {\r\n        min = d;\r\n        index = i;\r\n      }\r\n    }\r\n    this.data.splice(index, 1);\r\n    this.labels.splice(index, 1);\r\n  }\r\n};\r\n\r\nmodule.exports = Manager;\r\n\n\n//# sourceURL=webpack:///./src/js/manager.js?");

/***/ }),

/***/ "./src/js/nn/convnet.js":
/*!******************************!*\
  !*** ./src/js/nn/convnet.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("\r\n// Random number utilities\r\nvar return_v = false;\r\nvar v_val = 0.0;\r\nvar gaussRandom = function() {\r\n    if(return_v) { \r\n        return_v = false;\r\n        return v_val; \r\n    }\r\n    var u = 2*Math.random()-1;\r\n    var v = 2*Math.random()-1;\r\n    var r = u*u + v*v;\r\n    if(r == 0 || r > 1) return gaussRandom();\r\n    var c = Math.sqrt(-2*Math.log(r)/r);\r\n    v_val = v*c; // cache this\r\n    return_v = true;\r\n    return u*c;\r\n}\r\n\r\nvar randf = function(a, b) { return Math.random()*(b-a)+a; }\r\nvar randi = function(a, b) { return Math.floor(Math.random()*(b-a)+a); }\r\nvar randn = function(mu, std){ return mu+gaussRandom()*std; }\r\n\r\n// Array utilities\r\nvar zeros = function(n) {\r\nif(typeof(n)==='undefined' || isNaN(n)) { return []; }\r\nif(typeof ArrayBuffer === 'undefined') {\r\n    // lacking browser support\r\n    var arr = new Array(n);\r\n    for(var i=0;i<n;i++) { arr[i]= 0; }\r\n    return arr;\r\n} else {\r\n    return new Float64Array(n);\r\n}\r\n}\r\n\r\nvar arrContains = function(arr, elt) {\r\nfor(var i=0,n=arr.length;i<n;i++) {\r\n    if(arr[i]===elt) return true;\r\n}\r\nreturn false;\r\n}\r\n\r\nvar arrUnique = function(arr) {\r\nvar b = [];\r\nfor(var i=0,n=arr.length;i<n;i++) {\r\n    if(!arrContains(b, arr[i])) {\r\n    b.push(arr[i]);\r\n    }\r\n}\r\nreturn b;\r\n}\r\n\r\n// return max and min of a given non-empty array.\r\nvar maxmin = function(w) {\r\nif(w.length === 0) { return {}; } // ... ;s\r\nvar maxv = w[0];\r\nvar minv = w[0];\r\nvar maxi = 0;\r\nvar mini = 0;\r\nvar n = w.length;\r\nfor(var i=1;i<n;i++) {\r\n    if(w[i] > maxv) { maxv = w[i]; maxi = i; } \r\n    if(w[i] < minv) { minv = w[i]; mini = i; } \r\n}\r\nreturn {maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv:maxv-minv};\r\n}\r\n\r\n// create random permutation of numbers, in range [0...n-1]\r\nvar randperm = function(n) {\r\nvar i = n,\r\n    j = 0,\r\n    temp;\r\nvar array = [];\r\nfor(var q=0;q<n;q++)array[q]=q;\r\nwhile (i--) {\r\n    j = Math.floor(Math.random() * (i+1));\r\n    temp = array[i];\r\n    array[i] = array[j];\r\n    array[j] = temp;\r\n}\r\nreturn array;\r\n}\r\n\r\n// sample from list lst according to probabilities in list probs\r\n// the two lists are of same size, and probs adds up to 1\r\nvar weightedSample = function(lst, probs) {\r\nvar p = randf(0, 1.0);\r\nvar cumprob = 0.0;\r\nfor(var k=0,n=lst.length;k<n;k++) {\r\n    cumprob += probs[k];\r\n    if(p < cumprob) { return lst[k]; }\r\n}\r\n}\r\n\r\n// syntactic sugar function for getting default parameter values\r\nvar getopt = function(opt, field_name, default_value) {\r\nif(typeof field_name === 'string') {\r\n    // case of single string\r\n    return (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;\r\n} else {\r\n    // assume we are given a list of string instead\r\n    var ret = default_value;\r\n    for(var i=0;i<field_name.length;i++) {\r\n    var f = field_name[i];\r\n    if (typeof opt[f] !== 'undefined') {\r\n        ret = opt[f]; // overwrite return value\r\n    }\r\n    }\r\n    return ret;\r\n}\r\n}\r\n\r\nfunction assert(condition, message) {\r\n    if (!condition) {\r\n        message = message || \"Assertion failed\";\r\n        if (typeof Error !== \"undefined\") {\r\n        throw new Error(message);\r\n        }\r\n        throw message; // Fallback\r\n    }\r\n}\r\n  \r\n\r\n// Vol is the basic building block of all data in a net.\r\n// it is essentially just a 3D volume of numbers, with a\r\n// width (sx), height (sy), and depth (depth).\r\n// it is used to hold data for all filters, all volumes,\r\n// all weights, and also stores all gradients w.r.t. \r\n// the data. c is optionally a value to initialize the volume\r\n// with. If c is missing, fills the Vol with random numbers.\r\n  const Vol = function(sx, sy, depth, c) {\r\n    // this is how you check if a variable is an array. Oh, Javascript :)\r\n    if(Object.prototype.toString.call(sx) === '[object Array]') {\r\n        // we were given a list in sx, assume 1D volume and fill it up\r\n        this.sx = 1;\r\n        this.sy = 1;\r\n        this.depth = sx.length;\r\n        // we have to do the following copy because we want to use\r\n        // fast typed arrays, not an ordinary javascript array\r\n        this.w = zeros(this.depth);\r\n        this.dw = zeros(this.depth);\r\n        for(var i=0;i<this.depth;i++) {\r\n        this.w[i] = sx[i];\r\n        }\r\n    } else {\r\n        // we were given dimensions of the vol\r\n        this.sx = sx;\r\n        this.sy = sy;\r\n        this.depth = depth;\r\n        var n = sx*sy*depth;\r\n        this.w = zeros(n);\r\n        this.dw = zeros(n);\r\n        if(typeof c === 'undefined') {\r\n            // weight normalization is done to equalize the output\r\n            // variance of every neuron, otherwise neurons with a lot\r\n            // of incoming connections have outputs of larger variance\r\n            var scale = Math.sqrt(1.0/(sx*sy*depth));\r\n            for(var i=0;i<n;i++) { \r\n                this.w[i] = randn(0.0, scale);\r\n            }\r\n        } else {\r\n            for(var i=0;i<n;i++) { \r\n              this.w[i] = c;\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nVol.prototype = {\r\n  get: function(x, y, d) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    return this.w[ix];\r\n  },\r\n  set: function(x, y, d, v) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    this.w[ix] = v; \r\n  },\r\n  add: function(x, y, d, v) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    this.w[ix] += v; \r\n  },\r\n  get_grad: function(x, y, d) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    return this.dw[ix]; \r\n  },\r\n  set_grad: function(x, y, d, v) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    this.dw[ix] = v; \r\n  },\r\n  add_grad: function(x, y, d, v) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    this.dw[ix] += v; \r\n  },\r\n  cloneAndZero: function() { return new Vol(this.sx, this.sy, this.depth, 0.0)},\r\n  clone: function() {\r\n    var V = new Vol(this.sx, this.sy, this.depth, 0.0);\r\n    var n = this.w.length;\r\n    for(var i=0;i<n;i++) { V.w[i] = this.w[i]; }\r\n    return V;\r\n  },\r\n  addFrom: function(V) { for(var k=0;k<this.w.length;k++) { this.w[k] += V.w[k]; }},\r\n  addFromScaled: function(V, a) { for(var k=0;k<this.w.length;k++) { this.w[k] += a*V.w[k]; }},\r\n  setConst: function(a) { for(var k=0;k<this.w.length;k++) { this.w[k] = a; }},\r\n\r\n  toJSON: function() {\r\n    // todo: we may want to only save d most significant digits to save space\r\n    var json = {}\r\n    json.sx = this.sx; \r\n    json.sy = this.sy;\r\n    json.depth = this.depth;\r\n    json.w = this.w;\r\n    return json;\r\n    // we wont back up gradients to save space\r\n  },\r\n  fromJSON: function(json) {\r\n    this.sx = json.sx;\r\n    this.sy = json.sy;\r\n    this.depth = json.depth;\r\n\r\n    var n = this.sx*this.sy*this.depth;\r\n    this.w = zeros(n);\r\n    this.dw = zeros(n);\r\n    // copy over the elements.\r\n    for(var i=0;i<n;i++) {\r\n      this.w[i] = json.w[i];\r\n    }\r\n  }\r\n}\r\n\r\n\r\n// Volume utilities\r\n// intended for use with data augmentation\r\n// crop is the size of output\r\n// dx,dy are offset wrt incoming volume, of the shift\r\n// fliplr is boolean on whether we also want to flip left<->right\r\nvar augment = function(V, crop, dx, dy, fliplr) {\r\n  // note assumes square outputs of size crop x crop\r\n  if(typeof(fliplr)==='undefined') var fliplr = false;\r\n  if(typeof(dx)==='undefined') var dx = randi(0, V.sx - crop);\r\n  if(typeof(dy)==='undefined') var dy = randi(0, V.sy - crop);\r\n  \r\n  // randomly sample a crop in the input volume\r\n  var W;\r\n  if(crop !== V.sx || dx!==0 || dy!==0) {\r\n    W = new Vol(crop, crop, V.depth, 0.0);\r\n    for(var x=0;x<crop;x++) {\r\n      for(var y=0;y<crop;y++) {\r\n        if(x+dx<0 || x+dx>=V.sx || y+dy<0 || y+dy>=V.sy) continue; // oob\r\n        for(var d=0;d<V.depth;d++) {\r\n          W.set(x,y,d,V.get(x+dx,y+dy,d)); // copy data over\r\n        }\r\n      }\r\n    }\r\n  } else {\r\n    W = V;\r\n  }\r\n\r\n  if(fliplr) {\r\n    // flip volume horziontally\r\n    var W2 = W.cloneAndZero();\r\n    for(var x=0;x<W.sx;x++) {\r\n      for(var y=0;y<W.sy;y++) {\r\n        for(var d=0;d<W.depth;d++) {\r\n          W2.set(x,y,d,W.get(W.sx - x - 1,y,d)); // copy data over\r\n        }\r\n      }\r\n    }\r\n    W = W2; //swap\r\n  }\r\n  return W;\r\n}\r\n\r\n// img is a DOM element that contains a loaded image\r\n// returns a Vol of size (W, H, 4). 4 is for RGBA\r\nvar img_to_vol = function(img, convert_grayscale) {\r\n\r\n  if(typeof(convert_grayscale)==='undefined') var convert_grayscale = false;\r\n\r\n  var canvas = document.createElement('canvas');\r\n  canvas.width = img.width;\r\n  canvas.height = img.height;\r\n  var ctx = canvas.getContext(\"2d\");\r\n\r\n  // due to a Firefox bug\r\n  try {\r\n    ctx.drawImage(img, 0, 0);\r\n  } catch (e) {\r\n    if (e.name === \"NS_ERROR_NOT_AVAILABLE\") {\r\n      // sometimes happens, lets just abort\r\n      return false;\r\n    } else {\r\n      throw e;\r\n    }\r\n  }\r\n\r\n  try {\r\n    var img_data = ctx.getImageData(0, 0, canvas.width, canvas.height);\r\n  } catch (e) {\r\n    if(e.name === 'IndexSizeError') {\r\n      return false; // not sure what causes this sometimes but okay abort\r\n    } else {\r\n      throw e;\r\n    }\r\n  }\r\n\r\n  // prepare the input: get pixels and normalize them\r\n  var p = img_data.data;\r\n  var W = img.width;\r\n  var H = img.height;\r\n  var pv = []\r\n  for(var i=0;i<p.length;i++) {\r\n    pv.push(p[i]/255.0-0.5); // normalize image pixels to [-0.5, 0.5]\r\n  }\r\n  var x = new Vol(W, H, 4, 0.0); //input volume (image)\r\n  x.w = pv;\r\n\r\n  if(convert_grayscale) {\r\n    // flatten into depth=1 array\r\n    var x1 = new Vol(W, H, 1, 0.0);\r\n    for(var i=0;i<W;i++) {\r\n      for(var j=0;j<H;j++) {\r\n        x1.set(i,j,0,x.get(i,j,0));\r\n      }\r\n    }\r\n    x = x1;\r\n  }\r\n\r\n  return x;\r\n}\r\n\r\n// This file contains all layers that do dot products with input,\r\n// but usually in a different connectivity pattern and weight sharing\r\n// schemes: \r\n// - FullyConn is fully connected dot products \r\n// - ConvLayer does convolutions (so weight sharing spatially)\r\n// putting them together in one file because they are very similar\r\n  const ConvLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.out_depth = opt.filters;\r\n  this.sx = opt.sx; // filter size. Should be odd if possible, it's cleaner.\r\n  this.in_depth = opt.in_depth;\r\n  this.in_sx = opt.in_sx;\r\n  this.in_sy = opt.in_sy;\r\n  \r\n  // optional\r\n  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\r\n  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 1; // stride at which we apply filters to input volume\r\n  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\r\n  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\r\n  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\r\n\r\n  // computed\r\n  // note we are doing floor, so if the strided convolution of the filter doesnt fit into the input\r\n  // volume exactly, the output volume will be trimmed and not contain the (incomplete) computed\r\n  // final application.\r\n  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\r\n  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\r\n  this.layer_type = 'conv';\r\n\r\n  // initializations\r\n  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\r\n  this.filters = [];\r\n  for(var i=0;i<this.out_depth;i++) { this.filters.push(new Vol(this.sx, this.sy, this.in_depth)); }\r\n  this.biases = new Vol(1, 1, this.out_depth, bias);\r\n}\r\n\r\nConvLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    // optimized code by @mdda that achieves 2x speedup over previous version\r\n\r\n    this.in_act = V;\r\n    var A = new Vol(this.out_sx |0, this.out_sy |0, this.out_depth |0, 0.0);\r\n    \r\n    var V_sx = V.sx |0;\r\n    var V_sy = V.sy |0;\r\n    var xy_stride = this.stride |0;\r\n\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var f = this.filters[d];\r\n      var x = -this.pad |0;\r\n      var y = -this.pad |0;\r\n      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\r\n        x = -this.pad |0;\r\n        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\r\n\r\n          // convolve centered at this particular location\r\n          var a = 0.0;\r\n          for(var fy=0;fy<f.sy;fy++) {\r\n            var oy = y+fy; // coordinates in the original input array coordinates\r\n            for(var fx=0;fx<f.sx;fx++) {\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\r\n                for(var fd=0;fd<f.depth;fd++) {\r\n                  // avoid function call overhead (x2) for efficiency, compromise modularity :(\r\n                  a += f.w[((f.sx * fy)+fx)*f.depth+fd] * V.w[((V_sx * oy)+ox)*V.depth+fd];\r\n                }\r\n              }\r\n            }\r\n          }\r\n          a += this.biases.w[d];\r\n          A.set(ax, ay, d, a);\r\n        }\r\n      }\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n\r\n    var V = this.in_act;\r\n    V.dw = zeros(V.w.length); // zero out gradient wrt bottom data, we're about to fill it\r\n\r\n    var V_sx = V.sx |0;\r\n    var V_sy = V.sy |0;\r\n    var xy_stride = this.stride |0;\r\n\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var f = this.filters[d];\r\n      var x = -this.pad |0;\r\n      var y = -this.pad |0;\r\n      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\r\n        x = -this.pad |0;\r\n        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\r\n\r\n          // convolve centered at this particular location\r\n          var chain_grad = this.out_act.get_grad(ax,ay,d); // gradient from above, from chain rule\r\n          for(var fy=0;fy<f.sy;fy++) {\r\n            var oy = y+fy; // coordinates in the original input array coordinates\r\n            for(var fx=0;fx<f.sx;fx++) {\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\r\n                for(var fd=0;fd<f.depth;fd++) {\r\n                  // avoid function call overhead (x2) for efficiency, compromise modularity :(\r\n                  var ix1 = ((V_sx * oy)+ox)*V.depth+fd;\r\n                  var ix2 = ((f.sx * fy)+fx)*f.depth+fd;\r\n                  f.dw[ix2] += V.w[ix1]*chain_grad;\r\n                  V.dw[ix1] += f.w[ix2]*chain_grad;\r\n                }\r\n              }\r\n            }\r\n          }\r\n          this.biases.dw[d] += chain_grad;\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    var response = [];\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l2_decay_mul: this.l2_decay_mul, l1_decay_mul: this.l1_decay_mul});\r\n    }\r\n    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\r\n    return response;\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.sx = this.sx; // filter size in x, y dims\r\n    json.sy = this.sy;\r\n    json.stride = this.stride;\r\n    json.in_depth = this.in_depth;\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.l1_decay_mul = this.l1_decay_mul;\r\n    json.l2_decay_mul = this.l2_decay_mul;\r\n    json.pad = this.pad;\r\n    json.filters = [];\r\n    for(var i=0;i<this.filters.length;i++) {\r\n      json.filters.push(this.filters[i].toJSON());\r\n    }\r\n    json.biases = this.biases.toJSON();\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.sx = json.sx; // filter size in x, y dims\r\n    this.sy = json.sy;\r\n    this.stride = json.stride;\r\n    this.in_depth = json.in_depth; // depth of input volume\r\n    this.filters = [];\r\n    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\r\n    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\r\n    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0;\r\n    for(var i=0;i<json.filters.length;i++) {\r\n      var v = new Vol(0,0,0,0);\r\n      v.fromJSON(json.filters[i]);\r\n      this.filters.push(v);\r\n    }\r\n    this.biases = new Vol(0,0,0,0);\r\n    this.biases.fromJSON(json.biases);\r\n  }\r\n}\r\n\r\n  const FullyConnLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  // ok fine we will allow 'filters' as the word as well\r\n  this.out_depth = typeof opt.num_neurons !== 'undefined' ? opt.num_neurons : opt.filters;\r\n\r\n  // optional \r\n  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\r\n  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'fc';\r\n\r\n  // initializations\r\n  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\r\n  this.filters = [];\r\n  for(var i=0;i<this.out_depth ;i++) { this.filters.push(new Vol(1, 1, this.num_inputs)); }\r\n  this.biases = new Vol(1, 1, this.out_depth, bias);\r\n};\r\n\r\nFullyConnLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var A = new Vol(1, 1, this.out_depth, 0.0);\r\n    var Vw = V.w;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var a = 0.0;\r\n      var wi = this.filters[i].w;\r\n      for(var d=0;d<this.num_inputs;d++) {\r\n        a += Vw[d] * wi[d]; // for efficiency use Vols directly for now\r\n      }\r\n      a += this.biases.w[i];\r\n      A.w[i] = a;\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  getFormula: function(input) {\r\n    let f;\r\n    let output = [];\r\n    for(let i=0;i<this.out_depth;i++) {\r\n      let wi = this.filters[i].w;\r\n      f = \"\";\r\n      for(let j=0;j<this.num_inputs;j++) {\r\n        if(j!==0 && wi[j]>0) f += \"+\";\r\n        f += wi[j].toPrecision(4)+\"*\"+input[j];\r\n      }\r\n      if(this.biases.w[i]>0) f += \"+\";\r\n      f += this.biases.w[i].toPrecision(4);\r\n      output.push(f);\r\n    }\r\n    return output;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act;\r\n    V.dw =  zeros(V.w.length); // zero out the gradient in input Vol\r\n    \r\n    // compute gradient wrt weights and data\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var tfi = this.filters[i];\r\n      var chain_grad = this.out_act.dw[i];\r\n      for(var d=0;d<this.num_inputs;d++) {\r\n        V.dw[d] += tfi.w[d]*chain_grad; // grad wrt input data\r\n        tfi.dw[d] += V.w[d]*chain_grad; // grad wrt params\r\n      }\r\n      this.biases.dw[i] += chain_grad;\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    var response = [];\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l1_decay_mul: this.l1_decay_mul, l2_decay_mul: this.l2_decay_mul});\r\n    }\r\n    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\r\n    return response;\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    json.l1_decay_mul = this.l1_decay_mul;\r\n    json.l2_decay_mul = this.l2_decay_mul;\r\n    json.filters = [];\r\n    for(var i=0;i<this.filters.length;i++) {\r\n      json.filters.push(this.filters[i].toJSON());\r\n    }\r\n    json.biases = this.biases.toJSON();\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\r\n    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\r\n    this.filters = [];\r\n    for(var i=0;i<json.filters.length;i++) {\r\n      var v = new Vol(0,0,0,0);\r\n      v.fromJSON(json.filters[i]);\r\n      this.filters.push(v);\r\n    }\r\n    this.biases = new Vol(0,0,0,0);\r\n    this.biases.fromJSON(json.biases);\r\n  }\r\n}\r\n\r\n  \r\n  const PoolLayer = function(opt) {\r\n\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.sx = opt.sx; // filter size\r\n  this.in_depth = opt.in_depth;\r\n  this.in_sx = opt.in_sx;\r\n  this.in_sy = opt.in_sy;\r\n\r\n  // optional\r\n  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\r\n  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 2;\r\n  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\r\n\r\n  // computed\r\n  this.out_depth = this.in_depth;\r\n  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\r\n  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\r\n  this.layer_type = 'pool';\r\n  // store switches for x,y coordinates for where the max comes from, for each output neuron\r\n  this.switchx =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n  this.switchy =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n}\r\n\r\nPoolLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\r\n    \r\n    var n=0; // a counter for switches\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var x = -this.pad;\r\n      var y = -this.pad;\r\n      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\r\n        y = -this.pad;\r\n        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\r\n\r\n          // convolve centered at this particular location\r\n          var a = -99999; // hopefully small enough ;\\\r\n          var winx=-1,winy=-1;\r\n          for(var fx=0;fx<this.sx;fx++) {\r\n            for(var fy=0;fy<this.sy;fy++) {\r\n              var oy = y+fy;\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V.sy && ox>=0 && ox<V.sx) {\r\n                var v = V.get(ox, oy, d);\r\n                // perform max pooling and store pointers to where\r\n                // the max came from. This will speed up backprop \r\n                // and can help make nice visualizations in future\r\n                if(v > a) { a = v; winx=ox; winy=oy;}\r\n              }\r\n            }\r\n          }\r\n          this.switchx[n] = winx;\r\n          this.switchy[n] = winy;\r\n          n++;\r\n          A.set(ax, ay, d, a);\r\n        }\r\n      }\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function() { \r\n    // pooling layers have no parameters, so simply compute \r\n    // gradient wrt data here\r\n    var V = this.in_act;\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n    var A = this.out_act; // computed in forward pass \r\n\r\n    var n = 0;\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var x = -this.pad;\r\n      var y = -this.pad;\r\n      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\r\n        y = -this.pad;\r\n        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\r\n\r\n          var chain_grad = this.out_act.get_grad(ax,ay,d);\r\n          V.add_grad(this.switchx[n], this.switchy[n], d, chain_grad);\r\n          n++;\r\n\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.sx = this.sx;\r\n    json.sy = this.sy;\r\n    json.stride = this.stride;\r\n    json.in_depth = this.in_depth;\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.pad = this.pad;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.sx = json.sx;\r\n    this.sy = json.sy;\r\n    this.stride = json.stride;\r\n    this.in_depth = json.in_depth;\r\n    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0; // backwards compatibility\r\n    this.switchx =  zeros(this.out_sx*this.out_sy*this.out_depth); // need to re-init these appropriately\r\n    this.switchy =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n  }\r\n}\r\n\r\n\r\n  const InputLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required: depth\r\n  this.out_depth = getopt(opt, ['out_depth', 'depth'], 0);\r\n\r\n  // optional: default these dimensions to 1\r\n  this.out_sx = getopt(opt, ['out_sx', 'sx', 'width'], 1);\r\n  this.out_sy = getopt(opt, ['out_sy', 'sy', 'height'], 1);\r\n  \r\n  // computed\r\n  this.layer_type = 'input';\r\n}\r\nInputLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V;\r\n    return this.out_act; // simply identity function for now\r\n  },\r\n  backward: function() { },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n  \r\n// Layers that implement a loss. Currently these are the layers that \r\n// can initiate a backward() pass. In future we probably want a more \r\n// flexible system that can accomodate multiple losses to do multi-task\r\n// learning, and stuff like that. But for now, one of the layers in this\r\n// file must be the final layer in a Net.\r\n\r\n// This is a classifier, with N discrete classes from 0 to N-1\r\n// it gets a stream of N incoming numbers and computes the softmax\r\n// function (exponentiate and normalize to sum to 1 as probabilities should)\r\n  const SoftmaxLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'softmax';\r\n}\r\n\r\nSoftmaxLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = new Vol(1, 1, this.out_depth, 0.0);\r\n\r\n    // compute max activation\r\n    var as = V.w;\r\n    var amax = V.w[0];\r\n    for(var i=1;i<this.out_depth;i++) {\r\n      if(as[i] > amax) amax = as[i];\r\n    }\r\n\r\n    // compute exponentials (carefully to not blow up)\r\n    var es =  zeros(this.out_depth);\r\n    var esum = 0.0;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var e = Math.exp(as[i] - amax);\r\n      esum += e;\r\n      es[i] = e;\r\n    }\r\n\r\n    // normalize and output to sum to one\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      es[i] /= esum;\r\n      A.w[i] = es[i];\r\n    }\r\n\r\n    this.es = es; // save these for backprop\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function(y) {\r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var indicator = i === y ? 1.0 : 0.0;\r\n      var mul = -(indicator - this.es[i]);\r\n      x.dw[i] = mul;\r\n    }\r\n\r\n    // loss is the class negative log likelihood\r\n    return -Math.log(this.es[y]);\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\n// implements an L2 regression cost layer,\r\n// so penalizes \\sum_i(||x_i - y_i||^2), where x is its input\r\n// and y is the user-provided array of \"correct\" values.\r\n  const RegressionLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'regression';\r\n}\r\n\r\nRegressionLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V;\r\n    return V; // identity function\r\n  },\r\n  // y is a list here of size num_inputs\r\n  // or it can be a number if only one value is regressed\r\n  // or it can be a struct {dim: i, val: x} where we only want to \r\n  // regress on dimension i and asking it to have value x\r\n  backward: function(y) { \r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n    var loss = 0.0;\r\n    if(y instanceof Array || y instanceof Float64Array) {\r\n      for(var i=0;i<this.out_depth;i++) {\r\n        var dy = x.w[i] - y[i];\r\n        x.dw[i] = dy;\r\n        loss += 0.5*dy*dy;\r\n      }\r\n    } else if(typeof y === 'number') {\r\n      // lets hope that only one number is being regressed\r\n      var dy = x.w[0] - y;\r\n      x.dw[0] = dy;\r\n      loss += 0.5*dy*dy;\r\n    } else {\r\n      // assume it is a struct with entries .dim and .val\r\n      // and we pass gradient only along dimension dim to be equal to val\r\n      var i = y.dim;\r\n      var yi = y.val;\r\n      var dy = x.w[i] - yi;\r\n      x.dw[i] = dy;\r\n      loss += 0.5*dy*dy;\r\n    }\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\n  const SVMLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'svm';\r\n}\r\n\r\nSVMLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V; // nothing to do, output raw scores\r\n    return V;\r\n  },\r\n  backward: function(y) {\r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n\r\n    // we're using structured loss here, which means that the score\r\n    // of the ground truth should be higher than the score of any other \r\n    // class, by a margin\r\n    var yscore = x.w[y]; // score of ground truth\r\n    var margin = 1.0;\r\n    var loss = 0.0;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      if(y === i) { continue; }\r\n      var ydiff = -yscore + x.w[i] + margin;\r\n      if(ydiff > 0) {\r\n        // violating dimension, apply loss\r\n        x.dw[i] += 1;\r\n        x.dw[y] -= 1;\r\n        loss += ydiff;\r\n      }\r\n    }\r\n\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\n  \r\n// Implements ReLU nonlinearity elementwise\r\n// x -> max(0, x)\r\n// the output is in [0, inf)\r\n  const ReluLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'relu';\r\n}\r\nReluLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.clone();\r\n    var N = V.w.length;\r\n    var V2w = V2.w;\r\n    for(var i=0;i<N;i++) { \r\n      if(V2w[i] < 0) V2w[i] = 0; // threshold at 0\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      if(V2.w[i] <= 0) V.dw[i] = 0; // threshold\r\n      else V.dw[i] = V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n// Implements Sigmoid nnonlinearity elementwise\r\n// x -> 1/(1+e^(-x))\r\n// so the output is between 0 and 1.\r\n  const SigmoidLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'sigmoid';\r\n}\r\nSigmoidLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.cloneAndZero();\r\n    var N = V.w.length;\r\n    var V2w = V2.w;\r\n    var Vw = V.w;\r\n    for(var i=0;i<N;i++) { \r\n      V2w[i] = 1.0/(1.0+Math.exp(-Vw[i]));\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      var v2wi = V2.w[i];\r\n      V.dw[i] =  v2wi * (1.0 - v2wi) * V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n// Implements Maxout nnonlinearity that computes\r\n// x -> max(x)\r\n// where x is a vector of size group_size. Ideally of course,\r\n// the input size should be exactly divisible by group_size\r\n  const MaxoutLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.group_size = typeof opt.group_size !== 'undefined' ? opt.group_size : 2;\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = Math.floor(opt.in_depth / this.group_size);\r\n  this.layer_type = 'maxout';\r\n\r\n  this.switches =  zeros(this.out_sx*this.out_sy*this.out_depth); // useful for backprop\r\n}\r\nMaxoutLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var N = this.out_depth; \r\n    var V2 = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\r\n\r\n    // optimization branch. If we're operating on 1D arrays we dont have\r\n    // to worry about keeping track of x,y,d coordinates inside\r\n    // input volumes. In convnets we do :(\r\n    if(this.out_sx === 1 && this.out_sy === 1) {\r\n      for(var i=0;i<N;i++) {\r\n        var ix = i * this.group_size; // base index offset\r\n        var a = V.w[ix];\r\n        var ai = 0;\r\n        for(var j=1;j<this.group_size;j++) {\r\n          var a2 = V.w[ix+j];\r\n          if(a2 > a) {\r\n            a = a2;\r\n            ai = j;\r\n          }\r\n        }\r\n        V2.w[i] = a;\r\n        this.switches[i] = ix + ai;\r\n      }\r\n    } else {\r\n      var n=0; // counter for switches\r\n      for(var x=0;x<V.sx;x++) {\r\n        for(var y=0;y<V.sy;y++) {\r\n          for(var i=0;i<N;i++) {\r\n            var ix = i * this.group_size;\r\n            var a = V.get(x, y, ix);\r\n            var ai = 0;\r\n            for(var j=1;j<this.group_size;j++) {\r\n              var a2 = V.get(x, y, ix+j);\r\n              if(a2 > a) {\r\n                a = a2;\r\n                ai = j;\r\n              }\r\n            }\r\n            V2.set(x,y,i,a);\r\n            this.switches[n] = ix + ai;\r\n            n++;\r\n          }\r\n        }\r\n      }\r\n\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = this.out_depth;\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n\r\n    // pass the gradient through the appropriate switch\r\n    if(this.out_sx === 1 && this.out_sy === 1) {\r\n      for(var i=0;i<N;i++) {\r\n        var chain_grad = V2.dw[i];\r\n        V.dw[this.switches[i]] = chain_grad;\r\n      }\r\n    } else {\r\n      // bleh okay, lets do this the hard way\r\n      var n=0; // counter for switches\r\n      for(var x=0;x<V2.sx;x++) {\r\n        for(var y=0;y<V2.sy;y++) {\r\n          for(var i=0;i<N;i++) {\r\n            var chain_grad = V2.get_grad(x,y,i);\r\n            V.set_grad(x,y,this.switches[n],chain_grad);\r\n            n++;\r\n          }\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.group_size = this.group_size;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n    this.group_size = json.group_size;\r\n    this.switches =  zeros(this.group_size);\r\n  }\r\n}\r\n\r\n// a helper function, since tanh is not yet part of ECMAScript. Will be in v6.\r\nfunction tanh(x) {\r\n  var y = Math.exp(2 * x);\r\n  return (y - 1) / (y + 1);\r\n}\r\n// Implements Tanh nnonlinearity elementwise\r\n// x -> tanh(x) \r\n// so the output is between -1 and 1.\r\n  const TanhLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'tanh';\r\n}\r\nTanhLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.cloneAndZero();\r\n    var N = V.w.length;\r\n    for(var i=0;i<N;i++) { \r\n      V2.w[i] = tanh(V.w[i]);\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  getFormula: function(input){\r\n    for(let i=0;i<input.length;i++) {\r\n      input[i]=\"tanh(\"+input[i]+\")\";\r\n    }\r\n    return input;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      var v2wi = V2.w[i];\r\n      V.dw[i] = (1.0 - v2wi * v2wi) * V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n\r\n// An inefficient dropout layer\r\n// Note this is not most efficient implementation since the layer before\r\n// computed all these activations and now we're just going to drop them :(\r\n// same goes for backward pass. Also, if we wanted to be efficient at test time\r\n// we could equivalently be clever and upscale during train and copy pointers during test\r\n// todo: make more efficient.\r\n  const DropoutLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'dropout';\r\n  this.drop_prob = typeof opt.drop_prob !== 'undefined' ? opt.drop_prob : 0.5;\r\n  this.dropped =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n}\r\nDropoutLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    if(typeof(is_training)==='undefined') { is_training = false; } // default is prediction mode\r\n    var V2 = V.clone();\r\n    var N = V.w.length;\r\n    if(is_training) {\r\n      // do dropout\r\n      for(var i=0;i<N;i++) {\r\n        if(Math.random()<this.drop_prob) { V2.w[i]=0; this.dropped[i] = true; } // drop!\r\n        else {this.dropped[i] = false;}\r\n      }\r\n    } else {\r\n      // scale the activations during prediction\r\n      for(var i=0;i<N;i++) { V2.w[i]*=this.drop_prob; }\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act; // dummy identity function for now\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var chain_grad = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      if(!(this.dropped[i])) { \r\n        V.dw[i] = chain_grad.dw[i]; // copy over the gradient\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.drop_prob = this.drop_prob;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n    this.drop_prob = json.drop_prob;\r\n  }\r\n}\r\n  \r\n  \r\n// a bit experimental layer for now. I think it works but I'm not 100%\r\n// the gradient check is a bit funky. I'll look into this a bit later.\r\n// Local Response Normalization in window, along depths of volumes\r\n  const LocalResponseNormalizationLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.k = opt.k;\r\n  this.n = opt.n;\r\n  this.alpha = opt.alpha;\r\n  this.beta = opt.beta;\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'lrn';\r\n\r\n  // checks\r\n  if(this.n%2 === 0) { console.log('WARNING n should be odd for LRN layer'); }\r\n}\r\nLocalResponseNormalizationLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = V.cloneAndZero();\r\n    this.S_cache_ = V.cloneAndZero();\r\n    var n2 = Math.floor(this.n/2);\r\n    for(var x=0;x<V.sx;x++) {\r\n      for(var y=0;y<V.sy;y++) {\r\n        for(var i=0;i<V.depth;i++) {\r\n\r\n          var ai = V.get(x,y,i);\r\n\r\n          // normalize in a window of size n\r\n          var den = 0.0;\r\n          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {\r\n            var aa = V.get(x,y,j);\r\n            den += aa*aa;\r\n          }\r\n          den *= this.alpha / this.n;\r\n          den += this.k;\r\n          this.S_cache_.set(x,y,i,den); // will be useful for backprop\r\n          den = Math.pow(den, this.beta);\r\n          A.set(x,y,i,ai/den);\r\n        }\r\n      }\r\n    }\r\n\r\n    this.out_act = A;\r\n    return this.out_act; // dummy identity function for now\r\n  },\r\n  backward: function() { \r\n    // evaluate gradient wrt data\r\n    var V = this.in_act; // we need to set dw of this\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n    var A = this.out_act; // computed in forward pass \r\n\r\n    var n2 = Math.floor(this.n/2);\r\n    for(var x=0;x<V.sx;x++) {\r\n      for(var y=0;y<V.sy;y++) {\r\n        for(var i=0;i<V.depth;i++) {\r\n\r\n          var chain_grad = this.out_act.get_grad(x,y,i);\r\n          var S = this.S_cache_.get(x,y,i);\r\n          var SB = Math.pow(S, this.beta);\r\n          var SB2 = SB*SB;\r\n\r\n          // normalize in a window of size n\r\n          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {              \r\n            var aj = V.get(x,y,j); \r\n            var g = -aj*this.beta*Math.pow(S,this.beta-1)*this.alpha/this.n*2*aj;\r\n            if(j===i) g+= SB;\r\n            g /= SB2;\r\n            g *= chain_grad;\r\n            V.add_grad(x,y,j,g);\r\n          }\r\n\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() { return []; },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.k = this.k;\r\n    json.n = this.n;\r\n    json.alpha = this.alpha; // normalize by size\r\n    json.beta = this.beta;\r\n    json.out_sx = this.out_sx; \r\n    json.out_sy = this.out_sy;\r\n    json.out_depth = this.out_depth;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.k = json.k;\r\n    this.n = json.n;\r\n    this.alpha = json.alpha; // normalize by size\r\n    this.beta = json.beta;\r\n    this.out_sx = json.out_sx; \r\n    this.out_sy = json.out_sy;\r\n    this.out_depth = json.out_depth;\r\n    this.layer_type = json.layer_type;\r\n  }\r\n}\r\n\r\n\r\n// Net manages a set of layers\r\n// For now constraints: Simple linear order of layers, first layer input last layer a cost layer\r\n  const Net = function(options) {\r\n  this.layers = [];\r\n}\r\n\r\nNet.prototype = {\r\n  \r\n  // takes a list of layer definitions and creates the network layer objects\r\n  makeLayers: function(defs) {\r\n\r\n    // few checks\r\n    assert(defs.length >= 2, 'Error! At least one input layer and one loss layer are required.');\r\n    assert(defs[0].type === 'input', 'Error! First layer must be the input layer, to declare size of inputs');\r\n\r\n    // desugar layer_defs for adding activation, dropout layers etc\r\n    var desugar = function() {\r\n      var new_defs = [];\r\n      for(var i=0;i<defs.length;i++) {\r\n        var def = defs[i];\r\n        \r\n        if(def.type==='softmax' || def.type==='svm') {\r\n          // add an fc layer here, there is no reason the user should\r\n          // have to worry about this and we almost always want to\r\n          new_defs.push({type:'fc', num_neurons: def.num_classes});\r\n        }\r\n\r\n        if(def.type==='regression') {\r\n          // add an fc layer here, there is no reason the user should\r\n          // have to worry about this and we almost always want to\r\n          new_defs.push({type:'fc', num_neurons: def.num_neurons});\r\n        }\r\n\r\n        if((def.type==='fc' || def.type==='conv') \r\n            && typeof(def.bias_pref) === 'undefined'){\r\n          def.bias_pref = 0.0;\r\n          if(typeof def.activation !== 'undefined' && def.activation === 'relu') {\r\n            def.bias_pref = 0.1; // relus like a bit of positive bias to get gradients early\r\n            // otherwise it's technically possible that a relu unit will never turn on (by chance)\r\n            // and will never get any gradient and never contribute any computation. Dead relu.\r\n          }\r\n        }\r\n\r\n        new_defs.push(def);\r\n\r\n        if(typeof def.activation !== 'undefined') {\r\n          if(def.activation==='relu') { new_defs.push({type:'relu'}); }\r\n          else if (def.activation==='sigmoid') { new_defs.push({type:'sigmoid'}); }\r\n          else if (def.activation==='tanh') { new_defs.push({type:'tanh'}); }\r\n          else if (def.activation==='maxout') {\r\n            // create maxout activation, and pass along group size, if provided\r\n            var gs = def.group_size !== 'undefined' ? def.group_size : 2;\r\n            new_defs.push({type:'maxout', group_size:gs});\r\n          }\r\n          else { console.log('ERROR unsupported activation ' + def.activation); }\r\n        }\r\n        if(typeof def.drop_prob !== 'undefined' && def.type !== 'dropout') {\r\n          new_defs.push({type:'dropout', drop_prob: def.drop_prob});\r\n        }\r\n\r\n      }\r\n      return new_defs;\r\n    }\r\n    defs = desugar(defs);\r\n\r\n    // create the layers\r\n    this.layers = [];\r\n    for(var i=0;i<defs.length;i++) {\r\n      var def = defs[i];\r\n      if(i>0) {\r\n        var prev = this.layers[i-1];\r\n        def.in_sx = prev.out_sx;\r\n        def.in_sy = prev.out_sy;\r\n        def.in_depth = prev.out_depth;\r\n      }\r\n\r\n      switch(def.type) {\r\n        case 'fc': this.layers.push(new  FullyConnLayer(def)); break;\r\n        case 'lrn': this.layers.push(new  LocalResponseNormalizationLayer(def)); break;\r\n        case 'dropout': this.layers.push(new  DropoutLayer(def)); break;\r\n        case 'input': this.layers.push(new  InputLayer(def)); break;\r\n        case 'softmax': this.layers.push(new  SoftmaxLayer(def)); break;\r\n        case 'regression': this.layers.push(new  RegressionLayer(def)); break;\r\n        case 'conv': this.layers.push(new  ConvLayer(def)); break;\r\n        case 'pool': this.layers.push(new  PoolLayer(def)); break;\r\n        case 'relu': this.layers.push(new  ReluLayer(def)); break;\r\n        case 'sigmoid': this.layers.push(new  SigmoidLayer(def)); break;\r\n        case 'tanh': this.layers.push(new  TanhLayer(def)); break;\r\n        case 'maxout': this.layers.push(new  MaxoutLayer(def)); break;\r\n        case 'svm': this.layers.push(new  SVMLayer(def)); break;\r\n        default: console.log('ERROR: UNRECOGNIZED LAYER TYPE: ' + def.type);\r\n      }\r\n    }\r\n  },\r\n\r\n  // forward prop the network. \r\n  // The trainer class passes is_training = true, but when this function is\r\n  // called from outside (not from the trainer), it defaults to prediction mode\r\n  forward: function(V, is_training) {\r\n    if(typeof(is_training) === 'undefined') is_training = false;\r\n    var act = this.layers[0].forward(V, is_training);\r\n    for(var i=1;i<this.layers.length;i++) {\r\n      act = this.layers[i].forward(act, is_training);\r\n    }\r\n    return act;\r\n  },\r\n\r\n  getFormula: function(input){\r\n    let formula = \"\";\r\n    let formule = input;\r\n\r\n    for(let i=1;i<this.layers.length;i++) { // per tutti gli strati che ci sono\r\n      if(this.layers[i].layer_type===\"fc\") { // quando c'è un full connected\r\n        formule = this.layers[i].getFormula(formule); // il numero di formule viene ridotto dal numero di input al numero di output\r\n      }\r\n      else if(this.layers[i].layer_type!==\"input\" && this.layers[i].layer_type!==\"softmax\" ){ //se non è uno strato di input, o quello softmax => applico la trasformazione\r\n        //layer della funzione tanh\r\n        formule = this.layers[i].getFormula(formule);\r\n      }\r\n    }\r\n\r\n    for(let i=0;i<formule.length;i++){\r\n      if(i===0)\r\n        formula+=formule[i];\r\n      else\r\n        formula+=\"-(\"+formule[i]+\")\";\r\n    }\r\n    console.info(\"formule\");\r\n    console.table(formule);\r\n    return formula;\r\n  },\r\n\r\n  getCostLoss: function(V, y) {\r\n    this.forward(V, false);\r\n    var N = this.layers.length;\r\n    var loss = this.layers[N-1].backward(y);\r\n    return loss;\r\n  },\r\n  \r\n  // backprop: compute gradients wrt all parameters\r\n  backward: function(y) {\r\n    var N = this.layers.length;\r\n    var loss = this.layers[N-1].backward(y); // last layer assumed to be loss layer\r\n    for(var i=N-2;i>=0;i--) { // first layer assumed input\r\n      this.layers[i].backward();\r\n    }\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() {\r\n    // accumulate parameters and gradients for the entire network\r\n    var response = [];\r\n    for(var i=0;i<this.layers.length;i++) {\r\n      var layer_reponse = this.layers[i].getParamsAndGrads();\r\n      for(var j=0;j<layer_reponse.length;j++) {\r\n        response.push(layer_reponse[j]);\r\n      }\r\n    }\r\n    return response;\r\n  },\r\n  getPrediction: function() {\r\n    // this is a convenience function for returning the argmax\r\n    // prediction, assuming the last layer of the net is a softmax\r\n    var S = this.layers[this.layers.length-1];\r\n    assert(S.layer_type === 'softmax', 'getPrediction function assumes softmax as last layer of the net!');\r\n\r\n    var p = S.out_act.w;\r\n    var maxv = p[0];\r\n    var maxi = 0;\r\n    for(var i=1;i<p.length;i++) {\r\n      if(p[i] > maxv) { maxv = p[i]; maxi = i;}\r\n    }\r\n    return maxi; // return index of the class with highest class probability\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.layers = [];\r\n    for(var i=0;i<this.layers.length;i++) {\r\n      json.layers.push(this.layers[i].toJSON());\r\n    }\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.layers = [];\r\n    for(var i=0;i<json.layers.length;i++) {\r\n      var Lj = json.layers[i]\r\n      var t = Lj.layer_type;\r\n      var L;\r\n      if(t==='input') { L = new  InputLayer(); }\r\n      if(t==='relu') { L = new  ReluLayer(); }\r\n      if(t==='sigmoid') { L = new  SigmoidLayer(); }\r\n      if(t==='tanh') { L = new  TanhLayer(); }\r\n      if(t==='dropout') { L = new  DropoutLayer(); }\r\n      if(t==='conv') { L = new  ConvLayer(); }\r\n      if(t==='pool') { L = new  PoolLayer(); }\r\n      if(t==='lrn') { L = new  LocalResponseNormalizationLayer(); }\r\n      if(t==='softmax') { L = new  SoftmaxLayer(); }\r\n      if(t==='regression') { L = new  RegressionLayer(); }\r\n      if(t==='fc') { L = new  FullyConnLayer(); }\r\n      if(t==='maxout') { L = new  MaxoutLayer(); }\r\n      if(t==='svm') { L = new  SVMLayer(); }\r\n      L.fromJSON(Lj);\r\n      this.layers.push(L);\r\n    }\r\n  }\r\n}\r\n\r\n\r\n  const Trainer = function(net, options) {\r\n\r\n  this.net = net;\r\n\r\n  var options = options || {};\r\n  this.learning_rate = typeof options.learning_rate !== 'undefined' ? options.learning_rate : 0.01;\r\n  this.l1_decay = typeof options.l1_decay !== 'undefined' ? options.l1_decay : 0.0;\r\n  this.l2_decay = typeof options.l2_decay !== 'undefined' ? options.l2_decay : 0.0;\r\n  this.batch_size = typeof options.batch_size !== 'undefined' ? options.batch_size : 1;\r\n  this.method = typeof options.method !== 'undefined' ? options.method : 'sgd'; // sgd/adagrad/adadelta/windowgrad/netsterov\r\n\r\n  this.momentum = typeof options.momentum !== 'undefined' ? options.momentum : 0.9;\r\n  this.ro = typeof options.ro !== 'undefined' ? options.ro : 0.95; // used in adadelta\r\n  this.eps = typeof options.eps !== 'undefined' ? options.eps : 1e-6; // used in adadelta\r\n\r\n  this.k = 0; // iteration counter\r\n  this.gsum = []; // last iteration gradients (used for momentum calculations)\r\n  this.xsum = []; // used in adadelta\r\n}\r\n\r\nTrainer.prototype = {\r\n  train: function(x, y) {\r\n\r\n    var start = new Date().getTime();\r\n    this.net.forward(x, true); // also set the flag that lets the net know we're just training\r\n    var end = new Date().getTime();\r\n    var fwd_time = end - start;\r\n\r\n    var start = new Date().getTime();\r\n    var cost_loss = this.net.backward(y);\r\n    var l2_decay_loss = 0.0;\r\n    var l1_decay_loss = 0.0;\r\n    var end = new Date().getTime();\r\n    var bwd_time = end - start;\r\n    \r\n    this.k++;\r\n    if(this.k % this.batch_size === 0) {\r\n\r\n      var pglist = this.net.getParamsAndGrads();\r\n\r\n      // initialize lists for accumulators. Will only be done once on first iteration\r\n      if(this.gsum.length === 0 && (this.method !== 'sgd' || this.momentum > 0.0)) {\r\n        // only vanilla sgd doesnt need either lists\r\n        // momentum needs gsum\r\n        // adagrad needs gsum\r\n        // adadelta needs gsum and xsum\r\n        for(var i=0;i<pglist.length;i++) {\r\n          this.gsum.push( zeros(pglist[i].params.length));\r\n          if(this.method === 'adadelta') {\r\n            this.xsum.push( zeros(pglist[i].params.length));\r\n          } else {\r\n            this.xsum.push([]); // conserve memory\r\n          }\r\n        }\r\n      }\r\n\r\n      // perform an update for all sets of weights\r\n      for(var i=0;i<pglist.length;i++) {\r\n        var pg = pglist[i]; // param, gradient, other options in future (custom learning rate etc)\r\n        var p = pg.params;\r\n        var g = pg.grads;\r\n\r\n        // learning rate for some parameters.\r\n        var l2_decay_mul = typeof pg.l2_decay_mul !== 'undefined' ? pg.l2_decay_mul : 1.0;\r\n        var l1_decay_mul = typeof pg.l1_decay_mul !== 'undefined' ? pg.l1_decay_mul : 1.0;\r\n        var l2_decay = this.l2_decay * l2_decay_mul;\r\n        var l1_decay = this.l1_decay * l1_decay_mul;\r\n\r\n        var plen = p.length;\r\n        for(var j=0;j<plen;j++) {\r\n          l2_decay_loss += l2_decay*p[j]*p[j]/2; // accumulate weight decay loss\r\n          l1_decay_loss += l1_decay*Math.abs(p[j]);\r\n          var l1grad = l1_decay * (p[j] > 0 ? 1 : -1);\r\n          var l2grad = l2_decay * (p[j]);\r\n\r\n          var gij = (l2grad + l1grad + g[j]) / this.batch_size; // raw batch gradient\r\n\r\n          var gsumi = this.gsum[i];\r\n          var xsumi = this.xsum[i];\r\n          if(this.method === 'adagrad') {\r\n            // adagrad update\r\n            gsumi[j] = gsumi[j] + gij * gij;\r\n            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij;\r\n            p[j] += dx;\r\n          } else if(this.method === 'windowgrad') {\r\n            // this is adagrad but with a moving window weighted average\r\n            // so the gradient is not accumulated over the entire history of the run. \r\n            // it's also referred to as Idea #1 in Zeiler paper on Adadelta. Seems reasonable to me!\r\n            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\r\n            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij; // eps added for better conditioning\r\n            p[j] += dx;\r\n          } else if(this.method === 'adadelta') {\r\n            // assume adadelta if not sgd or adagrad\r\n            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\r\n            var dx = - Math.sqrt((xsumi[j] + this.eps)/(gsumi[j] + this.eps)) * gij;\r\n            xsumi[j] = this.ro * xsumi[j] + (1-this.ro) * dx * dx; // yes, xsum lags behind gsum by 1.\r\n            p[j] += dx;\r\n          } else if(this.method === 'nesterov') {\r\n            var dx = gsumi[j];\r\n            gsumi[j] = gsumi[j] * this.momentum + this.learning_rate * gij;\r\n              dx = this.momentum * dx - (1.0 + this.momentum) * gsumi[j];\r\n              p[j] += dx;\r\n          } else {\r\n            // assume SGD\r\n            if(this.momentum > 0.0) {\r\n              // momentum update\r\n              var dx = this.momentum * gsumi[j] - this.learning_rate * gij; // step\r\n              gsumi[j] = dx; // back this up for next iteration of momentum\r\n              p[j] += dx; // apply corrected gradient\r\n            } else {\r\n              // vanilla sgd\r\n              p[j] +=  - this.learning_rate * gij;\r\n            }\r\n          }\r\n          g[j] = 0.0; // zero out gradient so that we can begin accumulating anew\r\n        }\r\n      }\r\n    }\r\n\r\n    // appending softmax_loss for backwards compatibility, but from now on we will always use cost_loss\r\n    // in future, TODO: have to completely redo the way loss is done around the network as currently \r\n    // loss is a bit of a hack. Ideally, user should specify arbitrary number of loss functions on any layer\r\n    // and it should all be computed correctly and automatically. \r\n    return {fwd_time: fwd_time, bwd_time: bwd_time, \r\n            l2_decay_loss: l2_decay_loss, l1_decay_loss: l1_decay_loss,\r\n            cost_loss: cost_loss, softmax_loss: cost_loss, \r\n            loss: cost_loss + l1_decay_loss + l2_decay_loss}\r\n  }\r\n}\r\n\r\n\r\n/*\r\nA MagicNet takes data: a list of convnetjs.Vol(), and labels\r\nwhich for now are assumed to be class indeces 0..K. MagicNet then:\r\n- creates data folds for cross-validation\r\n- samples candidate networks\r\n- evaluates candidate networks on all data folds\r\n- produces predictions by model-averaging the best networks\r\n*/\r\n  const MagicNet = function(data, labels, opt) {\r\n  var opt = opt || {};\r\n  if(typeof data === 'undefined') { data = []; }\r\n  if(typeof labels === 'undefined') { labels = []; }\r\n\r\n  // required inputs\r\n  this.data = data; // store these pointers to data\r\n  this.labels = labels;\r\n\r\n  // optional inputs\r\n  this.train_ratio = getopt(opt, 'train_ratio', 0.7);\r\n  this.num_folds = getopt(opt, 'num_folds', 10);\r\n  this.num_candidates = getopt(opt, 'num_candidates', 50); // we evaluate several in parallel\r\n  // how many epochs of data to train every network? for every fold?\r\n  // higher values mean higher accuracy in final results, but more expensive\r\n  this.num_epochs = getopt(opt, 'num_epochs', 50); \r\n  // number of best models to average during prediction. Usually higher = better\r\n  this.ensemble_size = getopt(opt, 'ensemble_size', 10);\r\n\r\n  // candidate parameters\r\n  this.batch_size_min = getopt(opt, 'batch_size_min', 10);\r\n  this.batch_size_max = getopt(opt, 'batch_size_max', 300);\r\n  this.l2_decay_min = getopt(opt, 'l2_decay_min', -4);\r\n  this.l2_decay_max = getopt(opt, 'l2_decay_max', 2);\r\n  this.learning_rate_min = getopt(opt, 'learning_rate_min', -4);\r\n  this.learning_rate_max = getopt(opt, 'learning_rate_max', 0);\r\n  this.momentum_min = getopt(opt, 'momentum_min', 0.9);\r\n  this.momentum_max = getopt(opt, 'momentum_max', 0.9);\r\n  this.neurons_min = getopt(opt, 'neurons_min', 5);\r\n  this.neurons_max = getopt(opt, 'neurons_max', 30);\r\n\r\n  // computed\r\n  this.folds = []; // data fold indices, gets filled by sampleFolds()\r\n  this.candidates = []; // candidate networks that are being currently evaluated\r\n  this.evaluated_candidates = []; // history of all candidates that were fully evaluated on all folds\r\n  this.unique_labels = arrUnique(labels);\r\n  this.iter = 0; // iteration counter, goes from 0 -> num_epochs * num_training_data\r\n  this.foldix = 0; // index of active fold\r\n\r\n  // callbacks\r\n  this.finish_fold_callback = null;\r\n  this.finish_batch_callback = null;\r\n\r\n  // initializations\r\n  if(this.data.length > 0) {\r\n    this.sampleFolds();\r\n    this.sampleCandidates();\r\n  }\r\n};\r\n\r\nMagicNet.prototype = {\r\n\r\n  // sets this.folds to a sampling of this.num_folds folds\r\n  sampleFolds: function() {\r\n    var N = this.data.length;\r\n    var num_train = Math.floor(this.train_ratio * N);\r\n    this.folds = []; // flush folds, if any\r\n    for(var i=0;i<this.num_folds;i++) {\r\n      var p = randperm(N);\r\n      this.folds.push({train_ix: p.slice(0, num_train), test_ix: p.slice(num_train, N)});\r\n    }\r\n  },\r\n\r\n  // returns a random candidate network\r\n  sampleCandidate: function() {\r\n    var input_depth = this.data[0].w.length;\r\n    var num_classes = this.unique_labels.length;\r\n\r\n    // sample network topology and hyperparameters\r\n    var layer_defs = [];\r\n    layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth: input_depth});\r\n    var nl = weightedSample([0,1,2,3], [0.2, 0.3, 0.3, 0.2]); // prefer nets with 1,2 hidden layers\r\n    for(var q=0;q<nl;q++) {\r\n      var ni = randi(this.neurons_min, this.neurons_max);\r\n      var act = ['tanh','maxout','relu'][randi(0,3)];\r\n      if(randf(0,1)<0.5) {\r\n        var dp = Math.random();\r\n        layer_defs.push({type:'fc', num_neurons: ni, activation: act, drop_prob: dp});\r\n      } else {\r\n        layer_defs.push({type:'fc', num_neurons: ni, activation: act});\r\n      }\r\n    }\r\n    layer_defs.push({type:'softmax', num_classes: num_classes});\r\n    var net = new Net();\r\n    net.makeLayers(layer_defs);\r\n\r\n    // sample training hyperparameters\r\n    var bs = randi(this.batch_size_min, this.batch_size_max); // batch size\r\n    var l2 = Math.pow(10, randf(this.l2_decay_min, this.l2_decay_max)); // l2 weight decay\r\n    var lr = Math.pow(10, randf(this.learning_rate_min, this.learning_rate_max)); // learning rate\r\n    var mom = randf(this.momentum_min, this.momentum_max); // momentum. Lets just use 0.9, works okay usually ;p\r\n    var tp = randf(0,1); // trainer type\r\n    var trainer_def;\r\n    if(tp<0.33) {\r\n      trainer_def = {method:'adadelta', batch_size:bs, l2_decay:l2};\r\n    } else if(tp<0.66) {\r\n      trainer_def = {method:'adagrad', learning_rate: lr, batch_size:bs, l2_decay:l2};\r\n    } else {\r\n      trainer_def = {method:'sgd', learning_rate: lr, momentum: mom, batch_size:bs, l2_decay:l2};\r\n    }\r\n    \r\n    var trainer = new Trainer(net, trainer_def);\r\n\r\n    var cand = {};\r\n    cand.acc = [];\r\n    cand.accv = 0; // this will maintained as sum(acc) for convenience\r\n    cand.layer_defs = layer_defs;\r\n    cand.trainer_def = trainer_def;\r\n    cand.net = net;\r\n    cand.trainer = trainer;\r\n    return cand;\r\n  },\r\n\r\n  // sets this.candidates with this.num_candidates candidate nets\r\n  sampleCandidates: function() {\r\n    this.candidates = []; // flush, if any\r\n    for(var i=0;i<this.num_candidates;i++) {\r\n      var cand = this.sampleCandidate();\r\n      this.candidates.push(cand);\r\n    }\r\n  },\r\n\r\n  step: function() {\r\n    \r\n    // run an example through current candidate\r\n    this.iter++;\r\n\r\n    // step all candidates on a random data point\r\n    var fold = this.folds[this.foldix]; // active fold\r\n    var dataix = fold.train_ix[randi(0, fold.train_ix.length)];\r\n    for(var k=0;k<this.candidates.length;k++) {\r\n      var x = this.data[dataix];\r\n      var l = this.labels[dataix];\r\n      this.candidates[k].trainer.train(x, l);\r\n    }\r\n\r\n    // process consequences: sample new folds, or candidates\r\n    var lastiter = this.num_epochs * fold.train_ix.length;\r\n    if(this.iter >= lastiter) {\r\n      // finished evaluation of this fold. Get final validation\r\n      // accuracies, record them, and go on to next fold.\r\n      var val_acc = this.evalValErrors();\r\n      for(var k=0;k<this.candidates.length;k++) {\r\n        var c = this.candidates[k];\r\n        c.acc.push(val_acc[k]);\r\n        c.accv += val_acc[k];\r\n      }\r\n      this.iter = 0; // reset step number\r\n      this.foldix++; // increment fold\r\n\r\n      if(this.finish_fold_callback !== null) {\r\n        this.finish_fold_callback();\r\n      }\r\n\r\n      if(this.foldix >= this.folds.length) {\r\n        // we finished all folds as well! Record these candidates\r\n        // and sample new ones to evaluate.\r\n        for(var k=0;k<this.candidates.length;k++) {\r\n          this.evaluated_candidates.push(this.candidates[k]);\r\n        }\r\n        // sort evaluated candidates according to accuracy achieved\r\n        this.evaluated_candidates.sort(function(a, b) { \r\n          return (a.accv / a.acc.length) \r\n                > (b.accv / b.acc.length) \r\n                ? -1 : 1;\r\n        });\r\n        // and clip only to the top few ones (lets place limit at 3*ensemble_size)\r\n        // otherwise there are concerns with keeping these all in memory \r\n        // if MagicNet is being evaluated for a very long time\r\n        if(this.evaluated_candidates.length > 3 * this.ensemble_size) {\r\n          this.evaluated_candidates = this.evaluated_candidates.slice(0, 3 * this.ensemble_size);\r\n        }\r\n        if(this.finish_batch_callback !== null) {\r\n          this.finish_batch_callback();\r\n        }\r\n        this.sampleCandidates(); // begin with new candidates\r\n        this.foldix = 0; // reset this\r\n      } else {\r\n        // we will go on to another fold. reset all candidates nets\r\n        for(var k=0;k<this.candidates.length;k++) {\r\n          var c = this.candidates[k];\r\n          var net = new Net();\r\n          net.makeLayers(c.layer_defs);\r\n          var trainer = new Trainer(net, c.trainer_def);\r\n          c.net = net;\r\n          c.trainer = trainer;\r\n        }\r\n      }\r\n    }\r\n  },\r\n\r\n  evalValErrors: function() {\r\n    // evaluate candidates on validation data and return performance of current networks\r\n    // as simple list\r\n    var vals = [];\r\n    var fold = this.folds[this.foldix]; // active fold\r\n    for(var k=0;k<this.candidates.length;k++) {\r\n      var net = this.candidates[k].net;\r\n      var v = 0.0;\r\n      for(var q=0;q<fold.test_ix.length;q++) {\r\n        var x = this.data[fold.test_ix[q]];\r\n        var l = this.labels[fold.test_ix[q]];\r\n        net.forward(x);\r\n        var yhat = net.getPrediction();\r\n        v += (yhat === l ? 1.0 : 0.0); // 0 1 loss\r\n      }\r\n      v /= fold.test_ix.length; // normalize\r\n      vals.push(v);\r\n    }\r\n    return vals;\r\n  },\r\n\r\n  // returns prediction scores for given test data point, as Vol\r\n  // uses an averaged prediction from the best ensemble_size models\r\n  // x is a Vol.\r\n  predict_soft: function(data) {\r\n    // forward prop the best networks\r\n    // and accumulate probabilities at last layer into a an output Vol\r\n\r\n    var eval_candidates = [];\r\n    var nv = 0;\r\n    if(this.evaluated_candidates.length === 0) {\r\n      // not sure what to do here, first batch of nets hasnt evaluated yet\r\n      // lets just predict with current candidates.\r\n      nv = this.candidates.length;\r\n      eval_candidates = this.candidates;\r\n    } else {\r\n      // forward prop the best networks from evaluated_candidates\r\n      nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\r\n      eval_candidates = this.evaluated_candidates\r\n    }\r\n\r\n    // forward nets of all candidates and average the predictions\r\n    var xout, n;\r\n    for(var j=0;j<nv;j++) {\r\n      var net = eval_candidates[j].net;\r\n      var x = net.forward(data);\r\n      if(j===0) { \r\n        xout = x; \r\n        n = x.w.length; \r\n      } else {\r\n        // add it on\r\n        for(var d=0;d<n;d++) {\r\n          xout.w[d] += x.w[d];\r\n        }\r\n      }\r\n    }\r\n    // produce average\r\n    for(var d=0;d<n;d++) {\r\n      xout.w[d] /= nv;\r\n    }\r\n    return xout;\r\n  },\r\n\r\n  predict: function(data) {\r\n    var xout = this.predict_soft(data);\r\n    if(xout.w.length !== 0) {\r\n      var stats = maxmin(xout.w);\r\n      var predicted_label = stats.maxi; \r\n    } else {\r\n      var predicted_label = -1; // error out\r\n    }\r\n    return predicted_label;\r\n\r\n  },\r\n\r\n  toJSON: function() {\r\n    // dump the top ensemble_size networks as a list\r\n    var nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\r\n    var json = {};\r\n    json.nets = [];\r\n    for(var i=0;i<nv;i++) {\r\n      json.nets.push(this.evaluated_candidates[i].net.toJSON());\r\n    }\r\n    return json;\r\n  },\r\n\r\n  fromJSON: function(json) {\r\n    this.ensemble_size = json.nets.length;\r\n    this.evaluated_candidates = [];\r\n    for(var i=0;i<this.ensemble_size;i++) {\r\n      var net = new Net();\r\n      net.fromJSON(json.nets[i]);\r\n      var dummy_candidate = {};\r\n      dummy_candidate.net = net;\r\n      this.evaluated_candidates.push(dummy_candidate);\r\n    }\r\n  },\r\n\r\n  // callback functions\r\n  // called when a fold is finished, while evaluating a batch\r\n  onFinishFold: function(f) { this.finish_fold_callback = f; },\r\n  // called when a batch of candidates has finished evaluating\r\n  onFinishBatch: function(f) { this.finish_batch_callback = f; }\r\n  \r\n};\r\n\r\nmodule.exports = {\r\n  Net: Net,\r\n  Trainer: Trainer,\r\n  Vol: Vol\r\n};\n\n//# sourceURL=webpack:///./src/js/nn/convnet.js?");

/***/ }),

/***/ "./src/js/nn/nn.js":
/*!*************************!*\
  !*** ./src/js/nn/nn.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const convnet = __webpack_require__(/*! ./convnet.js */ \"./src/js/nn/convnet.js\");\r\nconst Net = convnet.Net;\r\nconst Vol = convnet.Vol;\r\nconst Trainer = convnet.Trainer;\r\nconst NeuralNet = function() {};\r\nNeuralNet.prototype = {\r\n  train: function(data, labels) {\r\n    this.options = this.options || {};\r\n    let layer_defs = this.options.layer_defs || [];\r\n    if (layer_defs.length === 0) {\r\n      layer_defs.push({ type: \"input\", out_sx: 1, out_sy: 1, out_depth: 2 });\r\n      layer_defs.push({ type: \"fc\", num_neurons: 4, activation: \"tanh\" });\r\n      layer_defs.push({ type: \"fc\", num_neurons: 4, activation: \"tanh\" });\r\n      layer_defs.push({ type: \"fc\", num_neurons: 4, activation: \"tanh\" });\r\n      layer_defs.push({ type: \"softmax\", num_classes: 2 });\r\n    }\r\n\r\n    this.net = new Net();\r\n    this.net.makeLayers(layer_defs);\r\n\r\n    let training_options = this.options.training || {};\r\n    let trainer = new Trainer(this.net, {\r\n      learning_rate: training_options.learning_rate || 0.01,\r\n      momentum: training_options.momentum || 0.1,\r\n      batch_size: training_options.batch_size || 10,\r\n      l2_decay: training_options.l2_decay || 0.001\r\n    });\r\n\r\n    let maxiter = training_options.iters || 1000;\r\n    let zeroOneLabels = labels.map(label => (label === 1 ? 1 : 0));\r\n    for (let iters = 0; iters < maxiter; iters++) {\r\n      for (let i = 0; i < data.length; i++) {\r\n        trainer.train(new Vol(data[i]), zeroOneLabels[i]);\r\n      }\r\n    }\r\n  },\r\n  predict: function(point) {\r\n    let a = this.net.forward(new Vol(point), false);\r\n    return (Math.tanh(a.w[1] - a.w[0]) + 1) / 2;\r\n  },\r\n  predictClass: function(point) {\r\n    let a = this.net.forward(new Vol(point), false);\r\n    return a.w[0] > a.w[1] ? -1 : 1;\r\n  },\r\n  getOptions: function() {\r\n    let options = {\r\n      group: \"neural net\",\r\n      training: {\r\n        group: \"training\",\r\n        iters: {\r\n          id: \"iters\",\r\n          type: \"range\",\r\n          min: 0,\r\n          max: 10000,\r\n          step: 10,\r\n          value: 1000\r\n        },\r\n        learning_rate: {\r\n          id: \"learning_rate\",\r\n          type: \"range\",\r\n          min: 0,\r\n          max: 0.1,\r\n          step: 0.01,\r\n          value: 0.01\r\n        },\r\n        momentum: {\r\n          id: \"momentum\",\r\n          type: \"range\",\r\n          min: 0,\r\n          max: 0.2,\r\n          step: 0.01,\r\n          value: 0.1\r\n        },\r\n        batch_size: {\r\n          id: \"batch_size\",\r\n          type: \"range\",\r\n          min: 5,\r\n          max: 20,\r\n          step: 1,\r\n          value: 10\r\n        },\r\n        l2_decay: {\r\n          id: \"l2_decay\",\r\n          type: \"range\",\r\n          min: 0,\r\n          max: 0.05,\r\n          step: 0.01,\r\n          value: 0.01\r\n        }\r\n      }\r\n    };\r\n    return options;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options;\r\n  }\r\n};\r\n\r\nmodule.exports = NeuralNet;\r\n\n\n//# sourceURL=webpack:///./src/js/nn/nn.js?");

/***/ }),

/***/ "./src/js/randf/randf.js":
/*!*******************************!*\
  !*** ./src/js/randf/randf.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// MIT License\r\n// Andrej Karpathy\r\n\r\nconst utils = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\");\r\n\r\nconst RandomForest = function() {};\r\n\r\nRandomForest.prototype = {\r\n  /*\r\n    data is 2D array of size N x D of examples\r\n    labels is a 1D array of labels (only -1 or 1 for now). In future will support multiclass or maybe even regression\r\n    options.numTrees can be used to customize number of trees to train (default = 100)\r\n    options.maxDepth is the maximum depth of each tree in the forest (default = 4)\r\n    options.numTries is the number of random hypotheses generated at each node during training (default = 10)\r\n    options.trainFun is a function with signature \"function myWeakTrain(data, labels, ix, options)\". Here, ix is a list of\r\n                     indeces into data of the instances that should be payed attention to. Everything not in the list\r\n                     should be ignored. This is done for efficiency. The function should return a model where you store\r\n                     variables. (i.e. model = {}; model.myvar = 5;) This will be passed to testFun.\r\n    options.testFun is a function with signature \"funtion myWeakTest(inst, model)\" where inst is 1D array specifying an example,\r\n                     and model will be the same model that you return in options.trainFun. For example, model.myvar will be 5.\r\n                     see decisionStumpTrain() and decisionStumpTest() downstairs for example.\r\n    */\r\n  train: function(data, labels) {\r\n    this.options = this.options || {};\r\n    this.numTrees = this.options.numTrees || 100;\r\n\r\n    // initialize many trees and train them all independently\r\n    this.trees = new Array(this.numTrees);\r\n    for (let i = 0; i < this.numTrees; i++) {\r\n      this.trees[i] = new DecisionTree();\r\n      this.trees[i].train(data, labels, this.options);\r\n    }\r\n  },\r\n\r\n  /*\r\n    inst is a 1D array of length D of an example.\r\n    returns the probability of label 1, i.e. a number in range [0, 1]\r\n    */\r\n  predict: function(point) {\r\n    // have each tree predict and average out all votes\r\n    let dec = 0;\r\n    for (let i = 0; i < this.numTrees; i++) {\r\n      dec += this.trees[i].predictOne(point);\r\n    }\r\n    dec /= this.numTrees;\r\n    return dec;\r\n  },\r\n\r\n  predictClass: function(point) {\r\n    return this.predict(point) > 0.5 ? 1 : -1;\r\n  },\r\n\r\n  getOptions: function() {\r\n    let options = {\r\n      group: \"random forest\",\r\n      numTrees: {\r\n        id: \"numTrees\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 100,\r\n        step: 1,\r\n        value: 100\r\n      },\r\n      maxDepth: {\r\n        id: \"maxDepth\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 10,\r\n        step: 1,\r\n        value: 4\r\n      },\r\n      numTries: {\r\n        id: \"numTries\",\r\n        type: \"range\",\r\n        min: 1,\r\n        max: 100,\r\n        step: 1,\r\n        value: 10\r\n      }\r\n    };\r\n    return options;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options;\r\n  }\r\n};\r\n\r\n// represents a single decision tree\r\nconst DecisionTree = function() {};\r\n\r\nDecisionTree.prototype = {\r\n  train: function(data, labels, options) {\r\n    options = options || {};\r\n    let maxDepth = options.maxDepth || 4;\r\n    let weakType = options.type || 0;\r\n\r\n    let trainFun = decision2DStumpTrain;\r\n    let testFun = decision2DStumpTest;\r\n\r\n    if (options.trainFun) trainFun = options.trainFun;\r\n    if (options.testFun) testFun = options.testFun;\r\n\r\n    if (weakType === 0) {\r\n      trainFun = decisionStumpTrain;\r\n      testFun = decisionStumpTest;\r\n    }\r\n    if (weakType === 1) {\r\n      trainFun = decision2DStumpTrain;\r\n      testFun = decision2DStumpTest;\r\n    }\r\n\r\n    // initialize various helper variables\r\n    let numInternals = Math.pow(2, maxDepth) - 1;\r\n    let numNodes = Math.pow(2, parseInt(maxDepth) + 1) - 1;\r\n    let ixs = new Array(numNodes);\r\n    for (let i = 1; i < ixs.length; i++) ixs[i] = [];\r\n    ixs[0] = new Array(labels.length);\r\n    for (let i = 0; i < labels.length; i++) ixs[0][i] = i; // root node starts out with all nodes as relevant\r\n    let models = new Array(numInternals);\r\n\r\n    // train\r\n    for (let n = 0; n < numInternals; n++) {\r\n      // few base cases\r\n      let ixhere = ixs[n];\r\n      if (ixhere.length === 0) {\r\n        continue;\r\n      }\r\n      if (ixhere.length === 1) {\r\n        ixs[n * 2 + 1] = [ixhere[0]];\r\n        continue;\r\n      } // arbitrary send it down left\r\n\r\n      // learn a weak model on relevant data for this node\r\n      let model = trainFun(data, labels, ixhere);\r\n      models[n] = model; // back it up model\r\n\r\n      // split the data according to the learned model\r\n      let ixleft = [];\r\n      let ixright = [];\r\n      for (let i = 0; i < ixhere.length; i++) {\r\n        let label = testFun(data[ixhere[i]], model);\r\n        if (label === 1) ixleft.push(ixhere[i]);\r\n        else ixright.push(ixhere[i]);\r\n      }\r\n      ixs[n * 2 + 1] = ixleft;\r\n      ixs[n * 2 + 2] = ixright;\r\n    }\r\n\r\n    // compute data distributions at the leafs\r\n    let leafPositives = new Array(numNodes);\r\n    let leafNegatives = new Array(numNodes);\r\n    for (let n = numInternals; n < numNodes; n++) {\r\n      let numones = 0;\r\n      for (let i = 0; i < ixs[n].length; i++) {\r\n        if (labels[ixs[n][i]] === 1) numones += 1;\r\n      }\r\n      leafPositives[n] = numones;\r\n      leafNegatives[n] = ixs[n].length - numones;\r\n    }\r\n\r\n    // back up important prediction variables for predicting later\r\n    this.models = models;\r\n    this.leafPositives = leafPositives;\r\n    this.leafNegatives = leafNegatives;\r\n    this.maxDepth = maxDepth;\r\n    this.trainFun = trainFun;\r\n    this.testFun = testFun;\r\n  },\r\n\r\n  // returns probability that example inst is 1.\r\n  predictOne: function(inst) {\r\n    let n = 0;\r\n    for (let i = 0; i < this.maxDepth; i++) {\r\n      let dir = this.testFun(inst, this.models[n]);\r\n      if (dir === 1) n = n * 2 + 1;\r\n      // descend left\r\n      else n = n * 2 + 2; // descend right\r\n    }\r\n\r\n    return (this.leafPositives[n] + 0.5) / (this.leafNegatives[n] + 1.0); // bayesian smoothing!\r\n  }\r\n};\r\n\r\n// returns model\r\nfunction decisionStumpTrain(data, labels, ix, options) {\r\n  options = options || {};\r\n  let numtries = options.numTries || 10;\r\n\r\n  // choose a dimension at random and pick a best split\r\n  let ri = utils.random.randi(0, data[0].length);\r\n  let N = ix.length;\r\n\r\n  // evaluate class entropy of incoming data\r\n  let H = entropy(labels, ix);\r\n  let bestGain = 0;\r\n  let bestThr = 0;\r\n  for (let i = 0; i < numtries; i++) {\r\n    // pick a random splitting threshold\r\n    let ix1 = ix[utils.random.randi(0, N)];\r\n    let ix2 = ix[utils.random.randi(0, N)];\r\n    while (ix2 === ix1) ix2 = ix[utils.random.randi(0, N)]; // enforce distinctness of ix2\r\n\r\n    let a = Math.random();\r\n    let thr = data[ix1][ri] * a + data[ix2][ri] * (1 - a);\r\n\r\n    // measure information gain we'd get from split with thr\r\n    let l1 = 1,\r\n      r1 = 1,\r\n      lm1 = 1,\r\n      rm1 = 1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1\r\n    for (let j = 0; j < ix.length; j++) {\r\n      if (data[ix[j]][ri] < thr) {\r\n        if (labels[ix[j]] === 1) l1++;\r\n        else lm1++;\r\n      } else {\r\n        if (labels[ix[j]] === 1) r1++;\r\n        else rm1++;\r\n      }\r\n    }\r\n    let t = l1 + lm1; // normalize the counts to obtain probability estimates\r\n    l1 = l1 / t;\r\n    lm1 = lm1 / t;\r\n    t = r1 + rm1;\r\n    r1 = r1 / t;\r\n    rm1 = rm1 / t;\r\n\r\n    let LH = -l1 * Math.log(l1) - lm1 * Math.log(lm1); // left and right entropy\r\n    let RH = -r1 * Math.log(r1) - rm1 * Math.log(rm1);\r\n\r\n    let informationGain = H - LH - RH;\r\n    //console.log(\"Considering split %f, entropy %f -> %f, %f. Gain %f\", thr, H, LH, RH, informationGain);\r\n    if (informationGain > bestGain || i === 0) {\r\n      bestGain = informationGain;\r\n      bestThr = thr;\r\n    }\r\n  }\r\n  return {\r\n    thr: bestThr,\r\n    ri: ri\r\n  };\r\n}\r\n\r\n// returns a decision for a single data instance\r\nfunction decisionStumpTest(inst, model) {\r\n  if (!model) {\r\n    // this is a leaf that never received any data...\r\n    return 1;\r\n  }\r\n  return inst[model.ri] < model.thr ? 1 : -1;\r\n}\r\n\r\n// returns model. Code duplication with decisionStumpTrain :(\r\nfunction decision2DStumpTrain(data, labels, ix, options) {\r\n  options = options || {};\r\n  let numtries = options.numTries || 10;\r\n\r\n  // choose a dimension at random and pick a best split\r\n  let N = ix.length;\r\n\r\n  let ri1 = 0;\r\n  let ri2 = 1;\r\n  if (data[0].length > 2) {\r\n    // more than 2D data. Pick 2 random dimensions\r\n    ri1 = utils.random.randi(0, data[0].length);\r\n    ri2 = utils.random.randi(0, data[0].length);\r\n    while (ri2 === ri1) ri2 = utils.random.randi(0, data[0].length); // must be distinct!\r\n  }\r\n\r\n  // evaluate class entropy of incoming data\r\n  let H = entropy(labels, ix);\r\n  let bestGain = 0;\r\n  let bestw1, bestw2, bestthr;\r\n  let dots = new Array(ix.length);\r\n  for (let i = 0; i < numtries; i++) {\r\n    // pick random line parameters\r\n    let alpha = utils.random.randf(0, 2 * Math.PI);\r\n    let w1 = Math.cos(alpha);\r\n    let w2 = Math.sin(alpha);\r\n\r\n    // project data on this line and get the dot products\r\n    for (let j = 0; j < ix.length; j++) {\r\n      dots[j] = w1 * data[ix[j]][ri1] + w2 * data[ix[j]][ri2];\r\n    }\r\n\r\n    // we are in a tricky situation because data dot product distribution\r\n    // can be skewed. So we don't want to select just randomly between\r\n    // min and max. But we also don't want to sort as that is too expensive\r\n    // let's pick two random points and make the threshold be somewhere between them.\r\n    // for skewed datasets, the selected points will with relatively high likelihood\r\n    // be in the high-desnity regions, so the thresholds will make sense\r\n    let ix1 = ix[utils.random.randi(0, N)];\r\n    let ix2 = ix[utils.random.randi(0, N)];\r\n    while (ix2 === ix1) ix2 = ix[utils.random.randi(0, N)]; // enforce distinctness of ix2\r\n    let a = Math.random();\r\n    let dotthr = dots[ix1] * a + dots[ix2] * (1 - a);\r\n\r\n    // measure information gain we'd get from split with thr\r\n    let l1 = 1,\r\n      r1 = 1,\r\n      lm1 = 1,\r\n      rm1 = 1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1\r\n    for (let j = 0; j < ix.length; j++) {\r\n      if (dots[j] < dotthr) {\r\n        if (labels[ix[j]] === 1) l1++;\r\n        else lm1++;\r\n      } else {\r\n        if (labels[ix[j]] === 1) r1++;\r\n        else rm1++;\r\n      }\r\n    }\r\n    let t = l1 + lm1;\r\n    l1 = l1 / t;\r\n    lm1 = lm1 / t;\r\n    t = r1 + rm1;\r\n    r1 = r1 / t;\r\n    rm1 = rm1 / t;\r\n\r\n    let LH = -l1 * Math.log(l1) - lm1 * Math.log(lm1); // left and right entropy\r\n    let RH = -r1 * Math.log(r1) - rm1 * Math.log(rm1);\r\n\r\n    let informationGain = H - LH - RH;\r\n    //console.log(\"Considering split %f, entropy %f -> %f, %f. Gain %f\", thr, H, LH, RH, informationGain);\r\n    if (informationGain > bestGain || i === 0) {\r\n      bestGain = informationGain;\r\n      bestw1 = w1;\r\n      bestw2 = w2;\r\n      bestthr = dotthr;\r\n    }\r\n  }\r\n\r\n  return {\r\n    w1: bestw1,\r\n    w2: bestw2,\r\n    dotthr: bestthr\r\n  };\r\n}\r\n\r\n// returns label for a single data instance\r\nfunction decision2DStumpTest(inst, model) {\r\n  if (!model) {\r\n    // this is a leaf that never received any data...\r\n    return 1;\r\n  }\r\n  return inst[0] * model.w1 + inst[1] * model.w2 < model.dotthr ? 1 : -1;\r\n}\r\n\r\n// Misc utility functions\r\nfunction entropy(labels, ix) {\r\n  let N = ix.length;\r\n  let p = 0.0;\r\n  for (let i = 0; i < N; i++) {\r\n    if (labels[ix[i]] === 1) p += 1;\r\n  }\r\n  p = (1 + p) / (N + 2); // let's be bayesian about this\r\n  let q = (1 + N - p) / (N + 2);\r\n  return -p * Math.log(p) - q * Math.log(q);\r\n}\r\n\r\nmodule.exports = RandomForest;\r\n\n\n//# sourceURL=webpack:///./src/js/randf/randf.js?");

/***/ }),

/***/ "./src/js/rbf/rbf.js":
/*!***************************!*\
  !*** ./src/js/rbf/rbf.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("const RBF = function() {};\r\nRBF.prototype = {\r\n  train: function(data, labels) {\r\n    this.data = data;\r\n    this.labels = labels;\r\n    this.options = this.options || {};\r\n    this.epsilon = this.options.epsilon || 0.1;\r\n    this.rbfSigma = this.options.rbfSigma || 0.5;\r\n  },\r\n  predict: function(point) {\r\n    return (Math.tanh(this.rbf(point) / Math.pow(this.epsilon, 2)) + 1) / 2;\r\n  },\r\n  predictClass: function(point) {\r\n    return this.rbf(point) > 0 ? 1 : -1;\r\n  },\r\n  rbf: function(point) {\r\n    let value = 0;\r\n    for (let i = 0; i < this.data.length; i++) {\r\n      let s = 0;\r\n      for (let j = 0; j < point.length; j++)\r\n        s += Math.pow(point[j] - this.data[i][j], 2);\r\n      value +=\r\n        this.labels[i] * Math.exp(-s / (2.0 * Math.pow(this.rbfSigma, 2)));\r\n    }\r\n    return value;\r\n  },\r\n  getOptions: function() {\r\n    let options = {\r\n      group: \"rbf\",\r\n      epsilon: {\r\n        id: \"epsilon\",\r\n        type: \"range\",\r\n        min: 0,\r\n        step: 0.1,\r\n        max: 2,\r\n        value: this.epsilon\r\n      },\r\n      rbfSigma: {\r\n        id: \"rbfSigma\",\r\n        type: \"range\",\r\n        min: 0,\r\n        step: 0.1,\r\n        max: 1,\r\n        value: this.rbfSigma\r\n      }\r\n    };\r\n    return options;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options;\r\n  }\r\n};\r\nmodule.exports = RBF;\r\n\n\n//# sourceURL=webpack:///./src/js/rbf/rbf.js?");

/***/ }),

/***/ "./src/js/svm/kernels.js":
/*!*******************************!*\
  !*** ./src/js/svm/kernels.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Kernels\r\n\r\nfunction makePolyKernel(d, c) {\r\n  return function(v1, v2) {\r\n    let s = 0;\r\n    for (let q = 0; q < v1.length; q++) {\r\n      s += v1[q] * v2[q];\r\n    }\r\n    s = s + c;\r\n    return Math.pow(s, d);\r\n  };\r\n}\r\n\r\nfunction makeSigmoidKernel(c) {\r\n  return function(v1, v2) {\r\n    let s = 0;\r\n    for (let q = 0; q < v1.length; q++) {\r\n      s += v1[q] * v2[q];\r\n    }\r\n    s = s + c;\r\n    return Math.tanh(s);\r\n  };\r\n}\r\n\r\nfunction makeRbfKernel(sigma) {\r\n  return function(v1, v2) {\r\n    let s = 0;\r\n    for (let q = 0; q < v1.length; q++) {\r\n      s += (v1[q] - v2[q]) * (v1[q] - v2[q]);\r\n    }\r\n    return Math.exp(-s / (2.0 * sigma * sigma));\r\n  };\r\n}\r\n\r\nfunction linearKernel(v1, v2) {\r\n  let s = 0;\r\n  for (let q = 0; q < v1.length; q++) {\r\n    s += v1[q] * v2[q];\r\n  }\r\n  return s;\r\n}\r\n\r\nmodule.exports = {\r\n  linearKernel: linearKernel,\r\n  makePolyKernel: makePolyKernel,\r\n  makeRbfKernel: makeRbfKernel,\r\n  makeSigmoidKernel: makeSigmoidKernel\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/svm/kernels.js?");

/***/ }),

/***/ "./src/js/svm/svm.js":
/*!***************************!*\
  !*** ./src/js/svm/svm.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const kernels = __webpack_require__(/*! ./kernels.js */ \"./src/js/svm/kernels.js\");\r\nconst linearKernel = kernels.linearKernel;\r\nconst makePolyKernel = kernels.makePolyKernel;\r\nconst makeRbfKernel = kernels.makeRbfKernel;\r\nconst makeSigmoidKernel = kernels.makeSigmoidKernel;\r\nconst utils = __webpack_require__(/*! could-be-utils */ \"./node_modules/could-be-utils/index.js\");\r\n\r\nlet svm_id=1;\r\nconst SVM = function() {\r\n    this.svm_id = svm_id++;\r\n};\r\n\r\nSVM.prototype = {\r\n\r\n    setOptions: function(options) {\r\n        this.options = options;\r\n    },\r\n\r\n    getOptions: function(){\r\n        let options = {\r\n            group:\"svm \"+this.svm_id,\r\n            C: {\r\n                id:\"C\",\r\n                type: \"range\",\r\n                min: 0,\r\n                max: 2,\r\n                step: 0.1,\r\n                value: this.C\r\n            },\r\n            karpathy:{\r\n                id:\"karpathy\",\r\n                type:\"checkbox\",\r\n                checked: true\r\n            },\r\n            memoize:{\r\n                id:\"memoize\",\r\n                type:\"checkbox\",\r\n                checked: true\r\n            },\r\n            kernel:{\r\n                group:\"kernel\",\r\n                linear:{\r\n                    id:\"linear\",\r\n                    type:\"radio\",\r\n                    value:\"linear\",\r\n                    name:\"kernel\"+this.svm_id,\r\n                    checked: this.kernelType === \"linear\",\r\n                    disabled: true\r\n                },\r\n                poly: {\r\n                    id:\"poly\",\r\n                    type:\"radio\",\r\n                    value:\"poly\",\r\n                    name:\"kernel\"+this.svm_id,\r\n                    checked: this.kernelType === \"poly\",\r\n                    disabled: true\r\n                },\r\n                rbf:{\r\n                    id:\"rbf\",\r\n                    type:\"radio\",\r\n                    value:\"rbf\",\r\n                    name:\"kernel\"+this.svm_id,\r\n                    checked: this.kernelType === \"rbf\",\r\n                    disabled: true\r\n                }\r\n            }\r\n        };\r\n        if(this.kernelType === \"linear\"){\r\n            options.group = \"svm linear \"+this.svm_id;\r\n        }\r\n        else if(this.kernelType === \"poly\"){\r\n            options.group = \"svm poly \"+this.svm_id;\r\n            options.degree = {\r\n                id:\"degree\",\r\n                type: \"range\",\r\n                min: 2,\r\n                max: 5,\r\n                step: 1,\r\n                value: this.degree\r\n            };\r\n        }\r\n        else if(this.kernelType === \"rbf\"){\r\n            options.group = \"svm rbf \"+this.svm_id;\r\n            options.rbfSigma = {\r\n                id:\"rbfSigma\",\r\n                type: \"range\",\r\n                min: 0,\r\n                max: 1,\r\n                step: 0.1,\r\n                value: this.rbfSigma\r\n            };\r\n        }\r\n        return options;\r\n    },\r\n\r\n    train: function(data, labels) {\r\n\r\n        this.data = data;\r\n        this.labels = labels;\r\n\r\n        // parameters\r\n        // options = options || {};\r\n        this.options = this.options || {};\r\n        let options = this.options;\r\n        let C = options.C || 1.0; // C value. Decrease for more regularization\r\n        let tol = options.tol || 1e-4; // numerical tolerance. Don't touch unless you're pro\r\n        let alphatol = options.alphatol || 0; // non-support vectors for space and time efficiency are truncated. To guarantee correct result set this to 0 to do no truncating. If you want to increase efficiency, experiment with setting this little higher, up to maybe 1e-4 or so.\r\n        let maxiter = options.maxiter || 10000; // max number of iterations\r\n        let numpasses = options.numpasses || 10; // how many passes over data with no change before we halt? Increase for more precision.\r\n        let SSCA = options.SSCA || false; // smoothed separable case approximation algorithm\r\n        let UB = options.UB || 0.5;\r\n\r\n        this.C = C;\r\n        this.tol = tol;\r\n        this.alphatol = alphatol;\r\n        this.maxiter = maxiter;\r\n        this.numpasses = numpasses;\r\n        this.eps = 1e-3; // for the full implemented SMO algorithm\r\n\r\n        // instantiate kernel according to options. kernel can be given as string or as a custom function\r\n        let kernel = linearKernel;\r\n        this.kernelType = \"linear\";\r\n        let kernelType = \"linear\";\r\n        for (let d in this.options.kernel) {\r\n            if (this.options.kernel[d]) kernelType = d;\r\n            }\r\n        if(\"kernel\" in options) {\r\n            if(typeof kernelType === \"string\") {\r\n                // kernel was specified as a string. Handle these special cases appropriately\r\n                if(kernelType === \"linear\") {\r\n                    this.kernelType = \"linear\";\r\n                    kernel = linearKernel;\r\n                }\r\n                if(kernelType === \"rbf\") {\r\n                    let rbfSigma = options.rbfsigma || 0.5;\r\n                    this.rbfSigma = rbfSigma; // back this up\r\n                    this.kernelType = \"rbf\";\r\n                    kernel = makeRbfKernel(rbfSigma);\r\n                }\r\n                if(kernelType === \"poly\"){\r\n                    let degree = options.degree || 2;\r\n                    this.degree = degree;\r\n                    let influence = options.influence || 1;\r\n                    if(influence<0) //cannot be negative\r\n                        influence = 0; //setting to zero\r\n                    this.influence = influence;\r\n                    this.kernelType = \"poly\";\r\n                    kernel = makePolyKernel(degree, influence);\r\n                }\r\n                if(kernelType === \"sigm\"){\r\n                    let influence = options.influence || 1;\r\n                    if(influence<0) //cannot be negative\r\n                        influence = 0; //setting to zero\r\n                    this.influence = influence;\r\n                    this.kernelType = \"sigm\";\r\n                    kernel = makeSigmoidKernel(influence);\r\n                }\r\n            }\r\n            else {\r\n                // assume kernel was specified as a function. Let's just use it\r\n                this.kernelType = \"custom\";\r\n                kernel = options.kernel;\r\n            }\r\n        }\r\n\r\n        //kernel choice\r\n        this.kernel = kernel;\r\n        //initializations\r\n        this.N = this.data.length;\r\n        this.D = this.data[0].length;\r\n        this.alpha = utils.array.zeros(this.N);\r\n        this.b = 0.0;\r\n        this.usew_ = false; // internal efficiency flag\r\n\r\n        this.use_timer = options.timer;\r\n\r\n        if(this.use_timer) {\r\n            this.ctx = options.timer.ctx || null;\r\n            this.updateFrequency = options.timer.updateFrequency || null;\r\n            this.stepsFrequency = options.timer.stepsFrequency || null;\r\n        }\r\n\r\n        // Cache kernel computations to avoid expensive recomputation.\r\n        // This could use too much memory if N is large.\r\n        if (options.memoize) {\r\n            this.kernelResults = new Array(this.N);\r\n            for (let i=0;i<this.N;i++) {\r\n                this.kernelResults[i] = new Array(this.N);\r\n                for (let j=0;j<this.N;j++) {\r\n                    this.kernelResults[i][j] = this.kernel(data[i],data[j]);\r\n                }\r\n            }\r\n        }\r\n\r\n        this.karpathy = options.karpathy || false;\r\n        if(this.karpathy){\r\n            // run SMO algorithm\r\n            this.iter = 0;\r\n            this.passes = 0;\r\n\r\n            if(options.timer){\r\n                this.timerKarpathySMO();\r\n            }\r\n            else{\r\n                this.karpathySMO();\r\n                this.store();\r\n            }\r\n        }\r\n        else {\r\n            //FULL Sequential Minimal Optimization (J.Platt)\r\n            //find non-pruned solution for SVM\r\n            this.SMO();\r\n\r\n            //Smoothed Separable Case Approximation\r\n            if(SSCA){\r\n                this.SSCA(UB,options);\r\n                this.SMO();\r\n            }\r\n            this.store();\r\n        }\r\n\r\n    },\r\n\r\n    karpathySMO: function(){\r\n        while(this.passes < this.numpasses && this.iter < this.maxiter) {\r\n            this.karpathySMOtime();\r\n        }\r\n    },\r\n\r\n    timerKarpathySMO: function(){\r\n        let weights = [];\r\n        let updateFrequency = this.updateFrequency;\r\n        let stepsFrequency = this.stepsFrequency;\r\n        this.timerVar = setInterval(()=>{\r\n            if(this.passes < this.numpasses && this.iter < this.maxiter){\r\n                let times = 0;\r\n                while(this.passes < this.numpasses && this.iter < this.maxiter && times < stepsFrequency) {\r\n                    this.karpathySMOtime();\r\n                    times++;\r\n                }\r\n                let w = this.getWeights();\r\n                weights.push(w);\r\n                draw();\r\n                if(!this.input_transformation) {\r\n                    for (let i = 0; i < weights.length; i++)\r\n                        drawIntermidiate(this.ctx, weights[i]);\r\n                }\r\n            }\r\n            else{\r\n                clearInterval(this.timerVar);\r\n                this.store();\r\n                draw();\r\n                if(!this.input_transformation) {\r\n                    for (let i = 0; i < weights.length; i++)\r\n                        drawIntermidiate(this.ctx, weights[i]);\r\n                }\r\n            }\r\n        }, updateFrequency);\r\n    },\r\n\r\n    karpathySMOtime: function(){\r\n        let data = this.data;\r\n        let labels = this.labels;\r\n        let C = this.C;\r\n        let alphaChanged = 0;\r\n        for (let i = 0; i < this.N; i++) {\r\n\r\n            let Ei = this.marginOne(data[i]) - labels[i];\r\n            if ((labels[i] * Ei < -this.tol && this.alpha[i] < C)\r\n                || (labels[i] * Ei > this.tol && this.alpha[i] > 0)) {\r\n\r\n                // alpha_i needs updating! Pick a j to update it with\r\n                let j = i;\r\n                while (j === i) j = utils.random.randi(0, this.N);\r\n                let Ej = this.marginOne(data[j]) - labels[j];\r\n\r\n                // calculate L and H bounds for j to ensure we're in [0 C]x[0 C] box\r\n                let ai = this.alpha[i];\r\n                let aj = this.alpha[j];\r\n                let L = 0;\r\n                let H = C;\r\n                if (labels[i] === labels[j]) {\r\n                    L = Math.max(0, ai + aj - C);\r\n                    H = Math.min(C, ai + aj);\r\n                } else {\r\n                    L = Math.max(0, aj - ai);\r\n                    H = Math.min(C, C + aj - ai);\r\n                }\r\n\r\n                if (Math.abs(L - H) < 1e-4) continue;\r\n\r\n                let eta = 2 * this.kernelResult(i, j) - this.kernelResult(i, i) - this.kernelResult(j, j);\r\n                if (eta >= 0) continue;\r\n\r\n                // compute new alpha_j and clip it inside [0 C]x[0 C] box\r\n                // then compute alpha_i based on it.\r\n                let newaj = aj - labels[j] * (Ei - Ej) / eta;\r\n                if (newaj > H) newaj = H;\r\n                if (newaj < L) newaj = L;\r\n                if (Math.abs(aj - newaj) < 1e-4) continue;\r\n                this.alpha[j] = newaj;\r\n                let newai = ai + labels[i] * labels[j] * (aj - newaj);\r\n                this.alpha[i] = newai;\r\n\r\n                // update the bias term\r\n                let b1 = this.b - Ei - labels[i] * (newai - ai) * this.kernelResult(i, i)\r\n                    - labels[j] * (newaj - aj) * this.kernelResult(i, j);\r\n                let b2 = this.b - Ej - labels[i] * (newai - ai) * this.kernelResult(i, j)\r\n                    - labels[j] * (newaj - aj) * this.kernelResult(j, j);\r\n                this.b = 0.5 * (b1 + b2);\r\n                if (newai > 0 && newai < C) this.b = b1;\r\n                if (newaj > 0 && newaj < C) this.b = b2;\r\n\r\n                alphaChanged++;\r\n\r\n            } // end alpha_i needed updating\r\n        } // end for i=1..N\r\n        if(this.use_timer)\r\n            this.store();\r\n\r\n        if (alphaChanged === 0) this.passes++;\r\n        else this.passes = 0;\r\n\r\n        this.iter++;\r\n    },\r\n\r\n    store: function(){\r\n        // if the user was using a linear kernel, lets also compute and store the\r\n        // weights. This will speed up evaluations during testing time\r\n        if(this.kernelType === \"linear\" || (this.kernelType === \"poly\" &&  this.degree === 1)) {\r\n\r\n            // compute weights and store them\r\n            this.w = new Array(this.D);\r\n            let s;\r\n            for(let j=0;j<this.D;j++) {\r\n                s=0;\r\n                for(let i=0;i<this.data.length;i++) {\r\n                    s += this.alpha[i] * this.labels[i] * this.data[i][j];\r\n                }\r\n                this.w[j] = s;\r\n                this.usew_ = true;\r\n            }\r\n\r\n        }\r\n        else {\r\n            // okay, we need to retain all the support vectors in the training data,\r\n            // we can't just get away with computing the weights and throwing it out\r\n\r\n            // But! We only need to store the support vectors for evaluation of testing\r\n            // instances. So filter here based on this.alpha[i]. The training data\r\n            // for which this.alpha[i] = 0 is irrelevant for future.\r\n            let newdata = [];\r\n            let newlabels = [];\r\n            let newalpha = [];\r\n            for(let i=0;i<this.N;i++) {\r\n                if(this.alpha[i] > this.alphatol) { //only if they are useful\r\n                    newdata.push(this.data[i]);\r\n                    newlabels.push(this.labels[i]);\r\n                    newalpha.push(this.alpha[i]);\r\n                }\r\n            }\r\n\r\n            // store data and labels\r\n            this.data = newdata;\r\n            this.labels = newlabels;\r\n            this.alpha = newalpha;\r\n            this.N = this.data.length;\r\n        }\r\n    },\r\n\r\n    update: function(){\r\n        // update value\r\n        this.N = this.data.length;\r\n        this.D = this.data[0].length;\r\n\r\n    },\r\n\r\n    getMaxMargin(data){\r\n        let margins = this.margins(data);\r\n        let max = 0;\r\n        for(let i=0;i<margins.length;i++){\r\n            if(margins[i]>max){\r\n                max = Math.abs(margins[i]);\r\n            }\r\n        }\r\n        return max;\r\n    },\r\n\r\n    getMinMargin(data){\r\n        let margins = this.margins(data);\r\n        let min = 0;\r\n        for(let i=0;i<margins.length;i++){\r\n            if(margins[i]<min){\r\n                min = margins[i];\r\n            }\r\n        }\r\n        return min;\r\n    },\r\n\r\n    getFormulaLinear: function(wb){\r\n        let formula = \"\";\r\n        let value = 0;\r\n        let text = \"\";\r\n        let equation = \"\";\r\n        let res = {\r\n        html: \"\",\r\n        text: \"\",\r\n        equation: \"\"\r\n        };\r\n        let intro = \"f(\";\r\n        for(let i=0;i<wb.w.length;i++){\r\n            intro +=\"x\"+\"<sub>\"+i+\"</sub>\";\r\n            if(i<wb.w.length-1)\r\n                intro+=\",\";\r\n        }\r\n        intro +=\"): \";\r\n        for(let i=0;i<wb.w.length;i++){\r\n        value = wb.w[i].toPrecision(6);\r\n        if(value > 0) {\r\n            formula += \"+\" + value;\r\n            text += \"+\" + value;\r\n            equation += \"+\" +value;\r\n        }\r\n        else {\r\n            formula += value;\r\n            text += value;\r\n            equation += +value;\r\n        }\r\n        formula += \"*<strong>x\"+\"<sub>\"+i+\"</sub>\"+\"</strong>\";\r\n        text += \"*x\"+i;\r\n        equation += \"*x\"+i;\r\n    }\r\n\r\n    if(wb.b > 0) {\r\n        formula += \"+\" + wb.b.toPrecision(6);\r\n        text += \"+\" + wb.b.toPrecision(6);\r\n        equation += \"+\" + wb.b.toPrecision(6);\r\n    }\r\n    else {\r\n        formula += \"\" + wb.b.toPrecision(6);\r\n        text += \"\" + wb.b.toPrecision(6);\r\n        equation += \"\" + wb.b.toPrecision(6)+\"=0\";\r\n    }\r\n    res.html = \"<strong>\"+intro+\"</strong>\"+formula;\r\n    res.text = text;\r\n    res.equation = equation;\r\n    return res;\r\n    },\r\n\r\n    // inst is an array of length D. Returns margin of given example\r\n    // this is the core prediction function. All others are for convenience mostly\r\n    // and end up calling this one somehow.\r\n    marginOne: function(inst) {\r\n        //console.info(\"marginOne\");\r\n        let f = 0;\r\n        if(this.karpathy)\r\n            f = this.b;\r\n        else f = -this.b;\r\n        // if the linear kernel was used and w was computed and stored,\r\n        // (i.e. the svm has fully finished training)\r\n        // the internal class variable usew_ will be set to true.\r\n        if(this.usew_) { //only with linear kernel\r\n            // we can speed this up a lot by using the computed weights\r\n            // we computed these during train(). This is significantly faster\r\n            // than the version below\r\n            for(let j=0;j<this.D;j++) {\r\n                f += inst[j] * this.w[j];\r\n            }\r\n        }\r\n        else { // others kernel or not already finished computing the weights\r\n            for(let i=0;i<this.data.length;i++) { //for every data entry (N times)\r\n                f += this.alpha[i] * this.labels[i] * this.kernel(inst, this.data[i]); //sum of all these product, including kernel evaluation with\r\n            }\r\n        }\r\n\r\n        return f;\r\n    },\r\n\r\n    predictClass: function(inst) {\r\n        return this.marginOne(inst) >= 0 ? 1:-1;\r\n    },\r\n\r\n    predict:  function(inst){\r\n        return ((Math.tanh(this.marginOne(inst)))+1)/2;\r\n    },\r\n\r\n    // data is an NxD array. Returns array of margins.\r\n    margins: function(data) {\r\n\r\n        // go over support vectors and accumulate the prediction.\r\n        const N = data.length;\r\n        let margins = new Array(N);\r\n        for(let i=0;i<N;i++) {\r\n            margins[i] = this.marginOne(data[i]);\r\n        }\r\n        return margins;\r\n\r\n    },\r\n\r\n    //used just for memoize the values calculated from the kernel\r\n    kernelResult: function(i, j) {\r\n        if (this.kernelResults) {\r\n            return this.kernelResults[i][j];\r\n        }\r\n        return this.kernel(this.data[i], this.data[j]);\r\n    },\r\n\r\n    // THIS FUNCTION IS NOW DEPRECATED. WORKS FINE BUT NO NEED TO USE ANYMORE.\r\n    // LEAVING IT HERE JUST FOR BACKWARDS COMPATIBILITY FOR A WHILE.\r\n    // if we trained a linear svm, it is possible to calculate just the weights and the offset\r\n    // prediction is then yhat = sign(X * w + b)\r\n    getWeights: function() {\r\n        //if(this.usew_) return {w: this.w, b:this.b};\r\n        // DEPRECATED\r\n        let D = this.data[0].length;\r\n        let w = new Array(D);\r\n        for(let j=0;j<D;j++) {\r\n            let s= 0.0;\r\n            for(let i=0;i<N;i++) {\r\n                s+= this.alpha[i] * this.labels[i] * this.data[i][j];\r\n            }\r\n            w[j]= s;\r\n        }\r\n        return {w: w, b: this.b};\r\n    },\r\n\r\n    toJSON: function() {\r\n\r\n        if(this.kernelType === \"custom\") {\r\n            console.log(\"Can't save this SVM because it's using custom, unsupported kernel...\");\r\n            return {};\r\n        }\r\n\r\n        let json = {};\r\n        json.N = this.N;\r\n        json.D = this.D;\r\n        json.b = this.b;\r\n\r\n        json.kernelType = this.kernelType;\r\n        if(this.kernelType === \"linear\") {\r\n            // just back up the weights\r\n            json.w = this.w;\r\n        }\r\n        if(this.kernelType === \"rbf\") {\r\n            // we need to store the support vectors and the sigma\r\n            json.rbfSigma = this.rbfSigma;\r\n            json.data = this.data;\r\n            json.labels = this.labels;\r\n            json.alpha = this.alpha;\r\n        }\r\n        if(this.kernelType === \"poly\"){\r\n            //we need to store the support vectors, the influence and the degree\r\n            json.influence = this.influence;\r\n            json.degree = this.degree;\r\n            json.data = this.data;\r\n            json.labels = this.labels;\r\n            json.alpha = this.alpha;\r\n        }\r\n        return json;\r\n    },\r\n\r\n    fromJSON: function(json) {\r\n\r\n        this.N = json.N;\r\n        this.D = json.D;\r\n        this.b = json.b;\r\n\r\n        this.kernelType = json.kernelType;\r\n        if(this.kernelType === \"linear\") {\r\n\r\n            // load the weights!\r\n            this.w = json.w;\r\n            this.usew_ = true;\r\n            this.kernel = linearKernel; // this shouldn't be necessary\r\n        }\r\n        else if(this.kernelType === \"rbf\") {\r\n\r\n            // initialize the kernel\r\n            this.rbfSigma = json.rbfSigma;\r\n            this.kernel = makeRbfKernel(this.rbfSigma);\r\n\r\n            // load the support vectors\r\n            this.data = json.data;\r\n            this.labels = json.labels;\r\n            this.alpha = json.alpha;\r\n        }\r\n        else if(this.kernelType === \"poly\") {\r\n\r\n            // initialize the kernel\r\n            this.degree = json.degree;\r\n            this.influence = json.influence;\r\n            this.kernel = makePolyKernel(this.degree, this.influence);\r\n\r\n            // load the support vectors\r\n            this.data = json.data;\r\n            this.labels = json.labels;\r\n            this.alpha = json.alpha;\r\n        }\r\n        else {\r\n            console.log(\"ERROR! unrecognized kernel type.\" + this.kernelType);\r\n        }\r\n    },\r\n\r\n    //********** FULL SMO ALGORITHM\r\n\r\n    takeStep: function(i1,i2,i,j){\r\n        //console.info(\"trying taking step with \"+i+\",\"+j);\r\n        if(i === j) return 0; //basta controllare l'indice\r\n        //console.info(\"not equal, go on\");\r\n        let alph1 = this.alpha[i];\r\n        let alph2 = this.alpha[j];\r\n        let y1 = this.labels[i];\r\n        let y2 = this.labels[j];\r\n        let E1 = this.getE(i);\r\n        let E2 = this.getE(j);\r\n        let s = y1*y2;\r\n        //Compute L, H via equations (13) and (14)\r\n        let C = this.C; //utiliy variable\r\n        let L,H;\r\n        if(y1 === y2) {\r\n            L = Math.max(0, alph2+alph1-C);\r\n            H = Math.min(C, alph2+alph1);\r\n        }\r\n        else {\r\n            L = Math.max(0, alph2-alph1);\r\n            H = Math.min(C, C+alph2-alph1);\r\n        }\r\n        //console.info(\"L-H = \"+Math.abs(L-H)+\" < \"+1e-4+\" ?\");\r\n        if(L===H) return 0;\r\n        //console.info(\"no, go on\");\r\n        let k11 =this.kernelResult(i,i);\r\n        let k12 =this.kernelResult(i,j);\r\n        let k22 =this.kernelResult(j,j);\r\n        let eta = k11 + k22 - 2*k12;\r\n\r\n        let a1;\r\n        let a2;\r\n        if(eta > 0){\r\n            a2 = alph2 + y2*(E1-E2)/eta;\r\n            if(a2<L) a2 = L;\r\n            else if(a2>H) a2 = H;\r\n        }\r\n        else{\r\n            //console.info(\"eta <0\");\r\n            let f1 = y1*(E1+this.b)-alph1*this.kernelResult(i,i)-s*alph2*this.kernelResult(i,j);\r\n            let f2 = y2*(E2+this.b)-s*alph1*this.kernelResult(i,j)-alph2*this.kernelResult(j,j);\r\n            let L1 = alph1+s*(alph2-L);\r\n            let H1 = alph1+s*(alph2-H);\r\n            let Lobj = L1*f1-L*f2+0.5*L1*L1*this.kernelResult(i,i)+0.5*L*L*this.kernelResult(j,j)+s*L*L1*this.kernelResult(i,j);\r\n            let Hobj = H1*f1+H*f2+0.5*H1*H1*this.kernelResult(i,i)+0.5*H*H*this.kernelResult(j,j)+s*H*H1*this.kernelResult(i,j);\r\n\r\n            if(Lobj < Hobj-this.eps)\r\n                a2 = L;\r\n            else if( Lobj > Hobj+this.eps)\r\n                a2 = H;\r\n            else\r\n                a2 = alph2;\r\n            //this.alpha[i] = value; //risetto il valore a quello di prima\r\n        }\r\n        //console.info(\"a2-alph2 = \"+Math.abs(a2-alph2)+\" < \"+this.eps*(a2+alph2+this.eps)+\" ?\");\r\n        if(Math.abs(a2-alph2)<this.eps*(a2+alph2+this.eps))\r\n            return 0;\r\n        //console.info(\"No,you're done\");\r\n        a1 = alph1+s*(alph2-a2);\r\n\r\n        //console.info(\"updating\");\r\n        //Update threshold to reflect change in Lagrange multipliers\r\n        let b1 = this.b + E1 + y1*(a1-alph1)*this.kernelResult(i,i) + y2*(a2-alph2)*this.kernelResult(i,j);\r\n        let b2 = this.b + E2 + y1*(a1-alph1)*this.kernelResult(i,j) + y2*(a2-alph2)*this.kernelResult(j,j);\r\n        this.b = 0.5*(b1+b2);\r\n        if(a1 > 0 && a1 < C) this.b = b1;\r\n        if(a2 > 0 && a2 < C) this.b = b2;\r\n\r\n        if(this.kernelType === \"linear\") {\r\n            //console.info(\"store weights\");\r\n            // compute weights and store them\r\n            let D = this.data[0].length;\r\n            this.w = new Array(D);\r\n            for(let j=0;j<D;j++) {\r\n                let s=0.0;\r\n                for(let i=0;i<this.data.length;i++) {\r\n                    s += this.alpha[i] * this.labels[i] * this.data[i][j];\r\n                }\r\n                this.w[j] = s;\r\n                this.usew_ = true;\r\n            }\r\n        }\r\n        //Update error cache using new Lagrande multipliers\r\n        //************not implemented caching\r\n\r\n        //Store a1 in the alpha array\r\n        this.alpha[i] = a1;\r\n        //Store a2 in the alpha array\r\n        this.alpha[j] = a2;\r\n        //console.info(\"step taken\");\r\n        return 1;\r\n\r\n    },\r\n\r\n    notAtBoundsAlpha: function(){\r\n        let indexes = [];\r\n        for(let i=0;i<this.alpha.length;i++){\r\n            if(!this.isAtBounds(this.alpha[i]))\r\n                indexes.push(i);\r\n        }\r\n        return indexes;\r\n    },\r\n\r\n    isAtBounds: function(value){\r\n        return value === 0 || value === this.C;\r\n    },\r\n\r\n    getE: function(i){\r\n        return this.marginOne(this.data[i]) - this.labels[i];\r\n    },\r\n\r\n    getMaxStepAlpha: function(i){\r\n        let index = 0;\r\n        let E1 = this.getE(i);\r\n        //let E = new Array(this.data.length);\r\n        let E = [];\r\n        for(let j=0;j<this.data.length;j++){ //fill E vector\r\n            E.push(this.getE(i));\r\n        }\r\n        if(E1 > 0){ //if positive, find the min\r\n            let min = E[0];\r\n            for(let j=0;j<E.length;j++){ //sort the best\r\n                if(j!==i){\r\n                    if(min>E[j]) {\r\n                        index = j; // save the index\r\n                        min = E[j]; //new min\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        else{ //non-positive, find the max\r\n            let max = E[0];\r\n            for(let j=0;j<E.length;j++){ //sort the best\r\n                if(j!==i){\r\n                    if(max<E[j]){\r\n                        index = j; //save the index\r\n                        max = E[j]; //new max\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return index;\r\n    },\r\n\r\n    examineExample: function(i2, i){\r\n        //console.info(\"examineExample\");\r\n        //let labels = this.labels;\r\n        //let C = this.C;\r\n        //let tol = this.tol;\r\n        //let limit = this.data.length;\r\n        //***************\r\n        let y2 = this.labels[i];\r\n        let alph2 = this.alpha[i];\r\n        let E2 = this.getE(i);\r\n        let r2 = E2*y2;\r\n        let i1;\r\n        if( (r2 < -this.tol && alph2 < this.C) || (r2 > this.tol && alph2 > 0) ) {\r\n            let indexes = this.notAtBoundsAlpha();\r\n            if(indexes.length > 1){ //number of non-zero & non-C alpha > 1\r\n                let index = this.getMaxStepAlpha(i);\r\n                i1 = this.data[index];//result of second choice heuristic\r\n                if(this.takeStep(i1,i2,index,i)){\r\n                    return 1;\r\n                }\r\n            }\r\n\r\n            let counter=0;\r\n            let rand = utils.random.randi(0,indexes.length);\r\n            for(let j=rand;counter<indexes.length;j++){ //loop over all non-zero and non-C alpha, starting at a random point\r\n                if(j === indexes.length){\r\n                    j=-1;\r\n                    continue; //skip this cycle\r\n                }\r\n                i1 = this.data[indexes[j]];\r\n                if(this.takeStep(i1,i2,j,i))\r\n                    return 1;\r\n\r\n                counter++;\r\n            }\r\n\r\n            counter = 0;\r\n            rand = utils.random.randi(0,this.data.length);\r\n            for(let j=rand;counter<this.data.length;j++){ //loop over all possibile i1, starting at a random point\r\n                if(j === this.data.length){\r\n                    j=-1;\r\n                    continue; //skip this cycle\r\n                }\r\n                i1 = this.data[j];\r\n                //console.info(\"trying with index: \"+j);\r\n                if(this.takeStep(i1,i2,j,i))\r\n                    return 1;\r\n                counter++;\r\n            }\r\n        }\r\n        return 0;\r\n    },\r\n\r\n    SMO: function () {\r\n        console.info(\"🐻 SMO (Platt): \"+this.data.length);\r\n        this.update();\r\n        //let statistics = {};\r\n        if(this.N === 0) return 0; // statistics;\r\n        let numChanged  = 0;\r\n        let examineAll = 1;\r\n        this.iter = 0;\r\n        this.N = this.data.length; //length of training examples\r\n\r\n        while(numChanged > 0 || examineAll){ //outer loop\r\n            numChanged = 0;\r\n            if(examineAll){\r\n                for (let i=0;i<this.N;i++){ //loop over all training examples\r\n                    numChanged += this.examineExample(this.data[i],i);\r\n                }\r\n            }\r\n            else {\r\n                for (let i=0;i<this.N;i++){ //loop over examples\r\n                    if(!this.isAtBounds(this.alpha[i])){//where alpha is not 0 & not C\r\n                        numChanged += this.examineExample(this.data[i],i);\r\n                    }\r\n                }\r\n            }\r\n            if(examineAll === 1)\r\n                examineAll = 0;\r\n            else if( numChanged === 0)\r\n                examineAll = 1;\r\n            this.iter++;\r\n        }\r\n\r\n        /*\r\n        //run statistics evaluation\r\n        statistics = statisticEval(this.labels,this.predict(this.data));\r\n        statistics.data = this.data;\r\n        statistics.labels = this.labels;\r\n        statistics.iters = iter;\r\n        */\r\n\r\n        // this.ROC();\r\n\r\n        //this.check();\r\n\r\n        console.info(\"🐻 SMO end\");\r\n\r\n        //return statistics;\r\n    },\r\n\r\n    findMaxDistance: function(){\r\n        let max = this.marginOne(this.data[0]);\r\n        let value=0;\r\n        for(let i=0;i<this.data.length;i++){\r\n            value = Math.abs(this.marginOne(this.data[i]));\r\n            if(value > max){\r\n                max = value;\r\n            }\r\n        }\r\n        return max;\r\n    },\r\n\r\n    //********** SSCA\r\n    //********* Smoothed Separable Case Approximation\r\n\r\n    ruleA: function(i,labels){\r\n        console.info(\"ruleA\");\r\n        labels[i] = -labels[i];\r\n    },\r\n\r\n    ruleB: function(i,data,alpha,labels){\r\n        console.info(\"ruleB element: \"+i);\r\n        data.splice(i,1);\r\n        alpha.splice(i,1);\r\n        labels.splice(i,1);\r\n    },\r\n\r\n    marginSSCA: function(inst,data,alpha,labels){\r\n        let f = -this.b;\r\n        for(let i=0;i<data.length;i++) { //for every data entry (N times)\r\n            f += alpha[i] * labels[i] * this.kernel(inst, data[i]); //sum of all these product, including kernel evaluation with\r\n        }\r\n        return f;\r\n    },\r\n\r\n    SSCA: function (D,options) {\r\n        console.info(\"🍀 SSCA: \"+this.data.length);\r\n        let value;\r\n\r\n        let alpha = utils.array.copyArray(this.alpha);\r\n        let labels = utils.array.copyArray(this.labels);\r\n        let data = utils.array.copyArray(this.data);\r\n        let left = this.data.length;\r\n\r\n        //check conditions for rules A,B\r\n        for (let i = 0; i < left; i++) { //per N volte\r\n\r\n            value = this.marginSSCA(data[i],data,alpha,labels) * labels[i];\r\n            //SCA\r\n            if (value < 0) { //misclassified\r\n                this.ruleA(i,labels); //flip label\r\n                value = this.marginSSCA(data[i],data,alpha,labels) * labels[i];\r\n\r\n                if (value < 0) { //misclassified\r\n                    console.info(\"i:\" + i);\r\n                    this.ruleB(i,data,alpha,labels);\r\n                    i--;\r\n                    left--;\r\n                    continue; //vado avanti\r\n                }\r\n            }\r\n            //SSCA\r\n            if (value < D) { //misclassified if it's under a threshold D\r\n                console.info(\"under \" + D);\r\n                this.ruleB(i,data,alpha,labels);\r\n                i--;\r\n                left--;\r\n            }\r\n        }\r\n\r\n        this.data = data;\r\n        this.alpha = alpha;\r\n        this.labels = labels;\r\n\r\n        this.check();\r\n\r\n        options.SSCA = false; //not SSCA again after training\r\n        console.info(\"🍀 SSCA end\");\r\n    },\r\n\r\n    check: function () {\r\n        console.info(\"\\t🔍 CHECK\");\r\n        let value = 0;\r\n        let noOne = true;\r\n        for (let i = 0; i < this.data.length; i++) { //per tutti quelli che devo eliminare\r\n            value = this.marginOne(this.data[i]) * this.labels[i];\r\n            if (value < 0){ //still misclassified with this configuration\r\n                noOne = false;\r\n                console.info(\"\\t💀 \"+i+\":\" + value);\r\n            }\r\n        }\r\n        if(noOne) console.info(\"\\t✔️\");\r\n    }\r\n};\r\n\r\nmodule.exports = SVM;\n\n//# sourceURL=webpack:///./src/js/svm/svm.js?");

/***/ }),

/***/ "./src/js/ui.js":
/*!**********************!*\
  !*** ./src/js/ui.js ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\r\n * YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name ui.js\r\n * @description\r\n * A User Interface function: automatically generates the GUI using the \"getOptions\" method of each algorithm\r\n * @param {document} document\r\n * @copyright Davide Ghiotto\r\n */\r\nconst UI = function(document, dataset_generator) {\r\n  this.document = document;\r\n\r\n  this.options_container = document.createElement(\"div\");\r\n  this.options_container.id = \"options_container\";\r\n  this.options_container.classList.add(\"options_container\");\r\n  this.document.body.appendChild(this.options_container);\r\n\r\n  this.configurations = {};\r\n  this.sets = [];\r\n\r\n  this.dataset_generator = dataset_generator;\r\n};\r\nUI.prototype = {\r\n  /**\r\n   * @returns returns the configurations\r\n   */\r\n  getAllConfigurations: function() {\r\n    return this.configurations;\r\n  },\r\n  /**\r\n   *\r\n   * @param {*} set the algorithm or the drawer to where to get the options\r\n   */\r\n  getConfigFromSet: function(set) {\r\n    let group = set.getOptions().group;\r\n    return this.configurations[group][group];\r\n  },\r\n  setOptionsOfSet: function(set) {\r\n    set.setOptions(this.getConfigFromSet(set));\r\n  },\r\n  setAllOptions: function() {\r\n    this.sets.forEach(set => set.setOptions(this.getConfigFromSet(set)));\r\n  },\r\n  createOptionsFrom: function(set, container) {\r\n    let set_options = set.getOptions();\r\n    this.sets.push(set);\r\n    let config = {};\r\n    this.configurations[set_options.group] = config;\r\n    container = container || this.options_container;\r\n    this.recursive(set_options, container, config);\r\n  },\r\n  recursive: function(options, container, config) {\r\n    if (options.type !== undefined) {\r\n      let res = this.createProperty(options, config);\r\n      for (let child in res) container.appendChild(res[child]);\r\n    } else {\r\n      let new_container = this.document.createElement(\"div\");\r\n      new_container.classList.add(\"container\");\r\n      let new_config = {};\r\n      for (let option in options) {\r\n        if (option === \"group\") {\r\n          new_container.id = options.group;\r\n        } else {\r\n          this.recursive(options[option], new_container, new_config);\r\n        }\r\n      }\r\n      config[new_container.id] = new_config;\r\n      let title = this.document.createElement(\"p\");\r\n      title.classList.add(\"title\");\r\n      title.innerHTML = new_container.id + \" options\";\r\n      container.appendChild(title);\r\n      container.appendChild(new_container);\r\n    }\r\n  },\r\n  createProperty: function(property, config) {\r\n    let input = this.document.createElement(\"input\");\r\n    let label = this.document.createElement(\"label\");\r\n\r\n    for (let key in property) input[key] = property[key];\r\n\r\n    label.innerHTML = input.id;\r\n    label.for = input.id;\r\n\r\n    if (input.type === \"range\") {\r\n      config[input.id] = parseFloat(input.value);\r\n      let value = this.document.createElement(\"div\");\r\n      value.innerHTML = parseFloat(input.value);\r\n      input.addEventListener(\"change\", () => {\r\n        value.innerHTML = parseFloat(input.value);\r\n        config[input.id] = parseFloat(input.value);\r\n      });\r\n      return {\r\n        label: label,\r\n        input: input,\r\n        value: value\r\n      };\r\n    } else if (input.type === \"radio\") {\r\n      config[input.id] = input.checked;\r\n      input.addEventListener(\"change\", () => {\r\n        for (let c in config) config[c] = false;\r\n        config[input.id] = input.checked;\r\n      });\r\n      return {\r\n        label: label,\r\n        input: input\r\n      };\r\n    } else {\r\n      config[input.id] = input.checked;\r\n      input.addEventListener(\"change\", () => {\r\n        config[input.id] = input.checked;\r\n      });\r\n      return {\r\n        label: label,\r\n        input: input\r\n      };\r\n    }\r\n  },\r\n  generateDataSet: function(dataset_id, N) {\r\n    if (dataset_id === \"circle\") {\r\n      return this.dataset_generator.circleData(N);\r\n    } else if (dataset_id === \"multi-circle\") {\r\n      return this.dataset_generator.circleMultipleData(N);\r\n    } else if (dataset_id === \"exclusive\") {\r\n      return this.dataset_generator.exclusiveOrData(N);\r\n    } else if (dataset_id === \"gaussian\") {\r\n      return this.dataset_generator.gaussianData(N);\r\n    } else if (dataset_id === \"spiral\") {\r\n      return this.dataset_generator.spiralData(N);\r\n    } else if (dataset_id === \"stripes-v\") {\r\n      return this.dataset_generator.stripesVData(N);\r\n    } else if (dataset_id === \"stripes-h\") {\r\n      return this.dataset_generator.stripesHData(N);\r\n    } else if (dataset_id === \"random\") {\r\n      return this.dataset_generator.randomData(N);\r\n    }\r\n  }\r\n};\r\n\r\nmodule.exports = UI;\r\n\n\n//# sourceURL=webpack:///./src/js/ui.js?");

/***/ }),

/***/ "./test/index.js":
/*!***********************!*\
  !*** ./test/index.js ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/**\r\n * YOU DON'T NEED THIS FILE TO USE THE MACHINE LEARNING MODULES\r\n * @name index.js\r\n * @description\r\n * This file is just a presentation of the features inside this project.\r\n * You will find other components other than machine learning modules:\r\n * - UI : for the creation of the GUI options\r\n * - Manager: for the management of the data flow between algorithms\r\n * - Drawer: basically just controls the canvas and the graphic rappresentation of the algorithm results\r\n * @copyright Davide Ghiotto\r\n */\r\nconst modules = __webpack_require__(/*! ../src/js/index.js */ \"./src/js/index.js\");\r\n// machine learning modules\r\nconst SVM = modules.SVM;\r\nconst LOGREG = modules.LOGREG;\r\nconst KNN = modules.KNN;\r\nconst RBF = modules.RBF;\r\nconst RANDF = modules.RANDF;\r\nconst NeuralNet = modules.NN;\r\n// ui modules\r\nconst Manager = modules.Manager;\r\nconst UI = modules.UI;\r\nconst Drawer = modules.Drawer;\r\nconst dataset_generator = modules.dataset_generator;\r\n\r\n// controls the data between various algorithms\r\nlet manager = new Manager();\r\n// generate datasets\r\nlet generator = new dataset_generator();\r\n\r\nlet data = [\r\n  [1, 0],\r\n  [2, 3],\r\n  [5, 4],\r\n  [2, 7],\r\n  [0, 3],\r\n  [-1, 0],\r\n  [-3, -4],\r\n  [-2, -2],\r\n  [-1, -1],\r\n  [-5, -2]\r\n];\r\nlet labels = [1, 1, 1, 1, 1, -1, -1, -1, -1, -1];\r\n\r\nmanager.setDataSet(data, labels);\r\n\r\nlet svm_linear = new SVM();\r\nlet svm_linear_options = {\r\n  kernel: {\r\n    linear: true\r\n  },\r\n  degree: 1,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  input_functions: {},\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_linear.setOptions(svm_linear_options);\r\nsvm_linear.train(data, labels);\r\n\r\nlet svm_poly = new SVM();\r\nlet svm_poly_options = {\r\n  kernel: {\r\n    poly: true\r\n  },\r\n  degree: 2,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_poly.setOptions(svm_poly_options);\r\nsvm_poly.train(data, labels);\r\n\r\nlet svm_rbf = new SVM();\r\nlet svm_rbf_options = {\r\n  kernel: {\r\n    rbf: true\r\n  },\r\n  degree: 2,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_rbf.setOptions(svm_rbf_options);\r\nsvm_rbf.train(data, labels);\r\n\r\nlet knn = new KNN();\r\nlet knn_options = {\r\n  k: 3,\r\n  distance: {\r\n    minkowski: true\r\n  },\r\n  p: 1.5\r\n};\r\nknn.setOptions(knn_options);\r\nknn.train(data, labels);\r\n\r\nlet rbf = new RBF();\r\nlet rbf_options = {\r\n  epsilon: 0.1,\r\n  rbfSigma: 0.5\r\n};\r\nrbf.setOptions(rbf_options);\r\nrbf.train(data, labels);\r\n\r\nlet randf = new RANDF();\r\nlet randf_options = {\r\n  numTrees: 100\r\n};\r\nrandf.setOptions(randf_options);\r\nrandf.train(data, labels);\r\n\r\nlet logreg = new LOGREG();\r\nlet logreg_options = {};\r\nlogreg.setOptions(logreg_options);\r\nlogreg.train(data, labels);\r\n\r\nlet nn = new NeuralNet();\r\nlet nn_options = {};\r\nnn.setOptions(nn_options);\r\nnn.train(data, labels);\r\n\r\nlet drawers = [];\r\ndrawers.push(\r\n  new Drawer(svm_linear, document.getElementById(\"svm-linear-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    },\r\n    boosted: true\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(svm_poly, document.getElementById(\"svm-poly-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(svm_rbf, document.getElementById(\"svm-rbf-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(knn, document.getElementById(\"knn-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(rbf, document.getElementById(\"rbf-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(randf, document.getElementById(\"randf-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(logreg, document.getElementById(\"logreg-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\ndrawers.push(\r\n  new Drawer(nn, document.getElementById(\"nn-canvas\"), {\r\n    margin: {\r\n      soft: true\r\n    }\r\n  })\r\n);\r\n\r\ndocument.getElementById(\"go\").addEventListener(\"click\", () => {\r\n  ui.setAllOptions();\r\n  manager.notifyAll();\r\n});\r\n\r\nlet btns_exe = document.getElementsByClassName(\"execute\");\r\nfor (let i = 0; i < btns_exe.length; i++) {\r\n  btns_exe[i].addEventListener(\"click\", () => {\r\n    ui.setOptionsOfSet(drawers[i]);\r\n    manager.notify(drawers[i]);\r\n  });\r\n}\r\n\r\nlet N = 50;\r\nlet label_slider = document.createElement(\"label\");\r\nlabel_slider.innerHTML = \"N:\" + N;\r\nlabel_slider.for = \"N\";\r\nlet slider = document.createElement(\"input\");\r\nslider.id = \"N\";\r\nslider.type = \"range\";\r\nslider.value = 50;\r\nslider.min = 10;\r\nslider.max = 300;\r\nslider.step = 10;\r\nslider.addEventListener(\"change\", () => {\r\n  N = slider.value;\r\n  label_slider.innerHTML = \"N:\" + N;\r\n});\r\ndocument.getElementById(\"datasets\").appendChild(label_slider);\r\ndocument.getElementById(\"datasets\").appendChild(slider);\r\nlet ui = new UI(document, generator);\r\n\r\nlet dataset_btns = document.getElementsByClassName(\"datasets\");\r\nfor (let i = 0; i < dataset_btns.length; i++) {\r\n  dataset_btns[i].addEventListener(\"click\", () => {\r\n    let res = ui.generateDataSet(dataset_btns[i].id, N);\r\n    manager.setDataSet(res.data, res.labels);\r\n    manager.notifyAll();\r\n  });\r\n}\r\n\r\nui.createOptionsFrom(\r\n  svm_linear,\r\n  document.getElementById(\"svm-linear-options-algorithm\")\r\n);\r\nui.createOptionsFrom(\r\n  drawers[0],\r\n  document.getElementById(\"svm-linear-options-draw\")\r\n);\r\nui.createOptionsFrom(\r\n  svm_poly,\r\n  document.getElementById(\"svm-poly-options-algorithm\")\r\n);\r\nui.createOptionsFrom(\r\n  drawers[1],\r\n  document.getElementById(\"svm-poly-options-draw\")\r\n);\r\nui.createOptionsFrom(\r\n  svm_rbf,\r\n  document.getElementById(\"svm-rbf-options-algorithm\")\r\n);\r\nui.createOptionsFrom(\r\n  drawers[2],\r\n  document.getElementById(\"svm-rbf-options-draw\")\r\n);\r\nui.createOptionsFrom(knn, document.getElementById(\"knn-options-algorithm\"));\r\nui.createOptionsFrom(drawers[3], document.getElementById(\"knn-options-draw\"));\r\nui.createOptionsFrom(rbf, document.getElementById(\"rbf-options-algorithm\"));\r\nui.createOptionsFrom(drawers[4], document.getElementById(\"rbf-options-draw\"));\r\nui.createOptionsFrom(randf, document.getElementById(\"randf-options-algorithm\"));\r\nui.createOptionsFrom(drawers[5], document.getElementById(\"randf-options-draw\"));\r\nui.createOptionsFrom(\r\n  logreg,\r\n  document.getElementById(\"logreg-options-algorithm\")\r\n);\r\nui.createOptionsFrom(\r\n  drawers[6],\r\n  document.getElementById(\"logreg-options-draw\")\r\n);\r\nui.createOptionsFrom(nn, document.getElementById(\"nn-options-algorithm\"));\r\nui.createOptionsFrom(drawers[7], document.getElementById(\"nn-options-draw\"));\r\n\r\ndrawers.forEach(drawer => manager.subscribe(drawer));\r\nmanager.notifyAll();\r\n\n\n//# sourceURL=webpack:///./test/index.js?");

/***/ })

/******/ });